[["index.html", "Detecting Hexadirectional Signals in the Human Brain using R and FSL 1 Overview 1.1 Requirements 1.2 Workflow 1.3 Required packages", " Detecting Hexadirectional Signals in the Human Brain using R and FSL Jacob Bellmund 1 Overview Grid-like hexadirectional signals are thought of as a proxy-measure for the activity of grid cell populations (Doeller et al., Nature, 2010). The goal of this project is to showcase the analysis pipeline to detect these hexadirectional signals using FSL and R. Visualization by Jacob Bellmund, licensed under CC BY 4.0. The main idea of the analysis is illustrated in the figure above. In brief, the characteristic six-fold symmetric firing patterns of grid cells might, on the population level, result in a six-fold (i.e. hexadirectional) modulation of activity that can be picked up with fMRI (top left). Thus, we will analyze fMRI data as a function of movement direction through a virtual environment in a spatial navigation task. However, the orientation (or phase) of the hexadirectional signal relative to the virtual environment is unknown. One partition of the data will be use to estimate the orientation of the hexadirectional signal. This is accomplished by implementing a GLM that models navigation events, so movement trajectories through the virtual environment. Crucially, it includes two parametric modulators for these events, which are defined by the sine and cosine of the direction of the trajectory in 60°-space. So these regressors search for activity peaks every 60° as a function of the trajectory direction (top right). The parameter estimates of the sine and the cosine regressor are then combined to estimate the orientation of an underlying hexadirectional signal in the first data partition (bottom right). This estimate is then validated on the second data partition, where we test whether BOLD activity is higher when the participant moves along directions that are close to the estimated orientation. This can be done in different ways: Either using a cosine regressor that tests for a parametric 60° modulation, so high activity when running at 0°, 60°, 120° and so on relative to the estimated orientation. A second way of testing this modulation would be to use a contrast between trajectories aligned (within 15°) of the estimated orientation and misaligned (between 15° and 30° from the estimated orientation. Thus, the three major steps the code goes through are: GLM 1: fit sine and cosine regressor at given periodicity for navigation trajectories Estimate orientation of the periodic signal GLM 2: test signal modulations as a function of trajectory direction relative to estimated orientation 1.1 Requirements The code requires FSL to be installed and to be accessible from R. Additional packages will be installed, see below. If you don’t have FSL installed, you will have to do that first. See here for detailed instructions. The code will automatically download example data that is based on the GridCAT analysis toolbox for Matlab (Stangl et al., Frontiers in Neuroinformatics, 2017). Overall, you will need around 11 GB of free disk space. 1.2 Workflow I have tested this analysis pipeline on Mac OS and Linux. Below are some basic usage instructions for scientists at the MPI CBS that might be helpful for others, too. See 1.2.3 for how to start the analysis once everything is configured. 1.2.1 CBS iMac or Macbook On our CBS iMacs and Macbooks FSL should be installed per default, though you might have to configure FSL when using it for the first time. Start RStudio from the terminal using open -na Rstudio. 1.2.2 Remote Linux You can also run the pipeline via the CBS NoMachine Remote Linux service. When logged on to a remote Linux session, hop on a least-utilized latest-generation (-sL) compute server by typing getserver -sL in a fresh console window. I have checked that everything works when using the FSL version stored in /usr/share/fsl/5.0/bin/fsl, so configure your .bash_profile file in hu_yourusername accordingly. You can open RStudio by typing R+ --version 3.6.1 rstudio (you can also try different R versions of course, but not tested). For some reason, FSL does not work properly when using /usr/lib/fsl/5.0/fsl, which is what you get if you type FSL --cluster to start the FSL environment on the server. This is an issue we might have to solve when we later want to parallelize the analysis. 1.2.3 Running the analysis Once you are in RStudio, open the R project file called hexadirectional_signals.Rproj in the folder hexadirectional_signals_pipeline. This will set your working directory to this folder. From here you can run the entire analysis when typing bookdown::render_book() in the RStudio console. Thus, the bookdown package needs to be installed prior to running the analysis via install.packages(\"bookdown\"). This command will install the package to the default library location. Other required packages (see next section) will be installed if necessary and loaded when rendering the book. If this fails, e.g. because user input is required, try running the section below manually once to make sure all packages are installed correctly. 1.3 Required packages We begin by loading the required packages (after installing them if necessary). if (!require(bookdown)){install.packages(&quot;bookdown&quot;); library(&quot;bookdown&quot;)} if (!require(tidyverse)){install.packages(&quot;tidyverse&quot;); library(&quot;tidyverse&quot;)} if (!require(here)){install.packages(&quot;here&quot;); library(&quot;here&quot;)} if (!require(fslr)){install.packages(&quot;fslr&quot;); library(&quot;fslr&quot;)} if (!require(oro.nifti)){install.packages(&quot;oro.nifti&quot;); library(&quot;oro.nifti&quot;)} if (!require(cowplot)){install.packages(&quot;cowplot&quot;); library(&quot;cowplot&quot;)} if (!require(useful)){install.packages(&quot;useful&quot;); library(&quot;useful&quot;)} if (!require(circular)){install.packages(&quot;circular&quot;); library(&quot;circular&quot;)} if (!require(remotes)){install.packages(&quot;remotes&quot;); library(&quot;remotes&quot;)} if (!require(grateful)){remotes::install_github(&quot;Pakillo/grateful&quot;); library(&quot;grateful&quot;)} #if (!require(tidylog)){install.packages(&quot;tidylog&quot;); library(&quot;tidylog&quot;, warn.conflicts = FALSE)} # very helpful logs of dplyr functions, but too much output for now "],["example-data.html", "2 Example Data 2.1 Download Example Data 2.2 Rearrange data 2.3 Event Tables 2.4 fMRI", " 2 Example Data To run the analysis, we want to use example data provided with the GridCAT toolbox. 2.1 Download Example Data # create data folder if needed if(!dir.exists(here(&quot;data&quot;))){dir.create(here(&quot;data&quot;))} # download the zipped example data zip_fn &lt;- here(&quot;data&quot;, &quot;example_data.zip&quot;) if (!file.exists(zip_fn)){ # sometimes download takes longer than default of 60s, so set to 300s options(timeout=300) download.file(url=&quot;https://www.nitrc.org/frs/download.php/9738/ExampleData.zip//?i_agree=1&amp;download_now=1&quot;, destfile = zip_fn) # unpack unzip(zip_fn, exdir = here(&quot;data&quot;)) } 2.2 Rearrange data To make things look a bit more realistic, let’s rearrange some of the folders. For now, we will only be operating with one subject that has two runs. subjects &lt;- c(&quot;sub01&quot;) runs &lt;- c(&quot;run01&quot;, &quot;run02&quot;) # realignment parameters if(!dir.exists(here(&quot;data&quot;, &quot;AdditionalRegressors&quot;, &quot;sub01&quot;))){ dir.create(here(&quot;data&quot;, &quot;AdditionalRegressors&quot;, &quot;sub01&quot;), recursive = TRUE) file.copy(from = list.files(here(&quot;data&quot;, &quot;ExampleData&quot;, &quot;AdditionalRegressors&quot;), full.names = TRUE), to = here(&quot;data&quot;, &quot;AdditionalRegressors&quot;, &quot;sub01&quot;)) invisible(file.rename(from=list.files(here(&quot;data&quot;, &quot;AdditionalRegressors&quot;, &quot;sub01&quot;), full.names = TRUE), to = here(&quot;data&quot;, &quot;AdditionalRegressors&quot;, &quot;sub01&quot;, paste0(&quot;realignmentParameters_&quot;, runs, &quot;.txt&quot;)))) } # event tables if(!dir.exists(here(&quot;data&quot;, &quot;EventTables&quot;, &quot;sub01&quot;))){ dir.create(here(&quot;data&quot;, &quot;EventTables&quot;, &quot;sub01&quot;), recursive = TRUE) file.copy(from = list.files(here(&quot;data&quot;, &quot;ExampleData&quot;, &quot;EventTables&quot;), full.names = TRUE), to = here(&quot;data&quot;, &quot;EventTables&quot;, &quot;sub01&quot;)) invisible(file.rename(from=list.files(here(&quot;data&quot;, &quot;EventTables&quot;, &quot;sub01&quot;), full.names = TRUE), to = here(&quot;data&quot;, &quot;EventTables&quot;, &quot;sub01&quot;, paste0(&quot;eventTable_&quot;, runs, &quot;.txt&quot;)))) } # EC ROIs if(!dir.exists(here(&quot;data&quot;, &quot;masks&quot;, &quot;ROI_masks&quot;))){ dir.create(here(&quot;data&quot;, &quot;masks&quot;, &quot;ROI_masks&quot;), recursive = TRUE) file.copy(from = list.files(here(&quot;data&quot;, &quot;ExampleData&quot;, &quot;ROI_masks&quot;), full.names = TRUE), to = here(&quot;data&quot;, &quot;masks&quot;, &quot;ROI_masks&quot;)) } # fMRI data run 1 if(!dir.exists(here(&quot;data&quot;, &quot;FunctionalScans&quot;, &quot;3D&quot;, &quot;sub01&quot;, &quot;run01&quot;))){ dir.create(here(&quot;data&quot;, &quot;FunctionalScans&quot;, &quot;3D&quot;, &quot;sub01&quot;, &quot;run01&quot;), recursive = TRUE) invisible(file.copy(from = list.files(here(&quot;data&quot;, &quot;ExampleData&quot;, &quot;FunctionalScans&quot;, &quot;run1&quot;), full.names = TRUE), to = here(&quot;data&quot;, &quot;FunctionalScans&quot;, &quot;3D&quot;, &quot;sub01&quot;, &quot;run01&quot;))) } # fMRI data run 2 if(!dir.exists(here(&quot;data&quot;, &quot;FunctionalScans&quot;, &quot;3D&quot;, &quot;sub01&quot;, &quot;run02&quot;))){ dir.create(here(&quot;data&quot;, &quot;FunctionalScans&quot;, &quot;3D&quot;, &quot;sub01&quot;, &quot;run02&quot;), recursive = TRUE) invisible(file.copy(from = list.files(here(&quot;data&quot;, &quot;ExampleData&quot;, &quot;FunctionalScans&quot;, &quot;run2&quot;), full.names = TRUE), to = here(&quot;data&quot;, &quot;FunctionalScans&quot;, &quot;3D&quot;, &quot;sub01&quot;, &quot;run02&quot;))) } 2.3 Event Tables The event tables in the example data are in a slightly strange format with some missing values (i.e. no angle information for feedback events). Because these missing values are not NAs but literally empty, loading the files results in warnings about parsing issues. We write them to a file where the missing values are replaced with NAs. # initialize empty tibble to collect all event tables event_table_full &lt;- tibble() for (i_sub in subjects){ for (i_run in runs){ # read the data and add column names fn &lt;- here(&quot;data&quot;, &quot;EventTables&quot;, i_sub, paste0(&quot;eventTable_&quot;, i_run, &quot;.txt&quot;)) event_table &lt;- read_delim(fn, delim = &quot;;&quot;, col_names = FALSE, col_types = c(&quot;fddd&quot;)) colnames(event_table) &lt;- c(&quot;name&quot;, &quot;onset&quot;, &quot;duration&quot;, &quot;angle&quot;) # write to file fn &lt;- here(&quot;data&quot;, &quot;EventTables&quot;, i_sub, paste0(&quot;eventTable_&quot;, i_run, &quot;_jb.txt&quot;)) event_table %&gt;% write_delim(file = fn, delim = &quot;\\t&quot;, col_names = TRUE) event_table &lt;- event_table %&gt;% mutate(subID = i_sub, run = i_run) event_table_full &lt;- rbind(event_table_full, event_table) } } ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details head(event_table_full) ## # A tibble: 6 × 6 ## name onset duration angle subID run ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 translation 3.00 5.90 175. sub01 run01 ## 2 translation 17.9 3.43 275. sub01 run01 ## 3 feedback 24.0 2.03 NA sub01 run01 ## 4 translation 26.1 4.08 58.6 sub01 run01 ## 5 translation 31.5 3.23 58.6 sub01 run01 ## 6 translation 35.9 3.11 112. sub01 run01 For each translation (navigation) event, the event table has a duration and and angle value. As we don’t have the raw navigation data, all we can do here is plot overview of the lengths and directions of the trajectories. When working with actual data, we will have to make decisions about how to define a trajectory event and how to label it with an angle. This is particularly complex if participants travel in long paths with curves so that they navigate in multiple directions in a translation event. We might want to do some reading here to check how other people did this. 2.3.1 Trajectory duration # we are only interested in the trajectory events trajectory_events &lt;- event_table_full %&gt;% filter(name == &quot;translation&quot;) # histogram of durations ggplot(trajectory_events, aes(x=duration)) + geom_histogram(bins=30) + facet_grid(subID ~ run) + ggtitle(&quot;Duration of translation events&quot;) + theme_cowplot() 2.3.2 Angular Sampling One thing we want to be sure of is that all trajectory directions were sampled somewhat evenly. To do visualize the angular sampling, we plot a polar histogram with 36 bins (10 degree width). # make polar histogram across trajectory event angles ggplot(trajectory_events, aes(x=angle)) + coord_polar() + scale_x_continuous(limits = c(0,360)) + geom_freqpoly(bins = 36) + facet_grid(subID ~ run) + labs(title = &quot;Trajectory directions&quot;) + theme_minimal() ## Warning: Removed 2 row(s) containing missing values (geom_path). We can also test statistically if our angular sampling deviates from uniformity using a Rayleigh’s test. This test is implemented below for the entire set of samples (i.e. collapsed across runs). # Rayleigh test of uniformity circular::rayleigh.test(circular(trajectory_events$angle, type=&quot;angles&quot;, units = &quot;degrees&quot;)) ## ## Rayleigh Test of Uniformity ## General Unimodal Alternative ## ## Test Statistic: 0.0378 ## P-value: 0.7299 2.4 fMRI 2.4.1 Merge images of each run We have two runs of fMRI data from a navigation task. Because the toolbox is built for SPM, each volume is a separate file. Because this is annoying, let’s merge the images of each run to one 4-D file. for (i_sub in subjects){ for (i_run in runs){ # create folder for 4D images if necessary fmri_4d_dir &lt;- here(&quot;data&quot;, &quot;FunctionalScans&quot;, &quot;4D&quot;, i_sub, i_run) if (!dir.exists(fmri_4d_dir)){dir.create(fmri_4d_dir, recursive = TRUE)} # merge the individual niftis into 4D timeseries fn &lt;- file.path(fmri_4d_dir, paste0(i_run, &quot;.nii.gz&quot;)) if (!file.exists(fn)){ # find all the files and merge them using fslmerge in_files &lt;- dir(here(&quot;data&quot;, &quot;FunctionalScans&quot;, &quot;3D&quot;, i_sub, i_run), full.names = TRUE) fslmerge(in_files, outfile = fn, retimg = FALSE, direction = &quot;t&quot;, verbose = FALSE) # let&#39;s have a look at the first volume of the 4D image run_nii &lt;- readNIfTI2(fn) ortho2(run_nii[,,,1], add.orient = TRUE) } #system(sprintf(&quot;fslmerge -tr %s %s 1.5&quot;, fn, fn)) } } 2.4.2 Calculate tSNR calc_tSNR &lt;- function(fourD_fn=NULL, tMean_fn=NULL, tStd_fn=NULL, tSNR_fn=NULL){ # calculate temporal mean for each voxel fslr::fsl_maths(file = fourD_fn, opts = &quot;-Tmean&quot;, outfile = tMean_fn, verbose = FALSE, retimg = FALSE) # calculate temporal mean for each voxel fslr::fsl_maths(file = fourD_fn, opts = &quot;-Tstd&quot;, outfile = tStd_fn, verbose = FALSE, retimg = FALSE) # calculate tSNR for each voxel fslr::fsl_div(file = tMean_fn, file2 = tStd_fn, outfile = tSNR_fn, verbose = FALSE, retimg = FALSE) } for (i_sub in subjects){ for (i_run in runs){ # create folder for SNR images if necessary snr_dir &lt;- here(&quot;data&quot;, &quot;snr&quot;, i_sub, i_run) if (!dir.exists(snr_dir)){dir.create(snr_dir, recursive = TRUE)} if (!file.exists(file.path(snr_dir, &quot;tSNR.nii.gz&quot;))){ # calculate tSNR calc_tSNR(fourD_fn = here(&quot;data&quot;, &quot;FunctionalScans&quot;, &quot;4D&quot;, i_sub, i_run, paste0(i_run, &quot;.nii.gz&quot;)), tMean_fn = file.path(snr_dir, &quot;tMean.nii.gz&quot;), tStd_fn = file.path(snr_dir, &quot;tStd.nii.gz&quot;), tSNR_fn = file.path(snr_dir, &quot;tSNR.nii.gz&quot;)) } } } 2.4.3 Create quick brain mask To speed up the GLM, let’s quickly create a brain mask based on the temporal mean image that we can use to mask the functional images. After eye-balling the image, we use a value of 100 to create the mask. for (i_sub in subjects){ for (i_run in runs){ # create folder for mask images if necessary mask_dir &lt;- here(&quot;data&quot;, &quot;masks&quot;, &quot;brain_mask&quot;, i_sub, i_run) if (!dir.exists(mask_dir)){dir.create(mask_dir, recursive = TRUE)} mask_fn &lt;- file.path(mask_dir, &quot;brain_mask_tMean100.nii.gz&quot;) if (!file.exists(mask_fn)){ mask_nii &lt;- fslthresh(file = here(&quot;data&quot;, &quot;snr&quot;, i_sub, i_run, &quot;tMean.nii.gz&quot;), outfile = mask_fn, thresh = 100, opts = &quot;-bin&quot;, verbose=FALSE) ortho2(mask_nii) } } # create a joint mask # the code below will only work correctly for two runs! mask_fn &lt;- here(&quot;data&quot;, &quot;masks&quot;, &quot;brain_mask&quot;, i_sub, runs, &quot;brain_mask_tMean100.nii.gz&quot;) fslmul(mask_fn[1], mask_fn[2], outfile = here(&quot;data&quot;, &quot;masks&quot;, &quot;brain_mask&quot;, i_sub, &quot;comb_brain_mask_tMean100.nii.gz&quot;), retimg = FALSE, verbose=FALSE) } 2.4.4 Mask 4D functionals To speed up the GLM, we use the mask created above to mask out non-brain voxels from the functional images. for (i_sub in subjects){ for (i_run in runs){ # create folder for mask images if necessary func4d_dir &lt;- here(&quot;data&quot;, &quot;FunctionalScans&quot;, &quot;4D&quot;, i_sub, i_run) masked4D_fn &lt;- here(&quot;data&quot;, &quot;FunctionalScans&quot;, &quot;4D&quot;, i_sub, i_run, paste0(i_run, &quot;_masked.nii.gz&quot;)) if (!file.exists(masked4D_fn)){ fslmask(file = here(&quot;data&quot;, &quot;FunctionalScans&quot;, &quot;4D&quot;, i_sub, i_run, paste0(i_run, &quot;.nii.gz&quot;)), mask = here(&quot;data&quot;, &quot;masks&quot;, &quot;brain_mask&quot;, i_sub, i_run, &quot;brain_mask_tMean100.nii.gz&quot;), outfile = masked4D_fn, verbose = FALSE, retimg = FALSE) # let&#39;s have a look at the first volume of the resulting masked 4D image run_nii &lt;- readNIfTI2(masked4D_fn) ortho2(run_nii[,,,1], add.orient = TRUE) } } } "],["glm-1.html", "3 GLM 1 3.1 First half of each run", " 3 GLM 1 The central step of GLM 1 is to run a model including a regressor for navigation periods (defined as translational movements) and two (linear) parametric modulators for that regressor. The parametric modulators are the sine and the cosine of the movement direction of the navigation periods. The beta estimates of these regressors will be used to estimate the orientation of a six-fold signal that will be subject to further analyses in GLM 2. GLM 1 and GLM 2 operate on independent data partitions and there are multiple ways to partition the data: - use odd/even runs to train/test - split each run in half - use odd/even trajectories to train/test As far as I know, there are no systematic investigations into which method is best (most sensitive, most robust…). Depending on how the estimation and testing procedure is implemented, assumptions about the underlying grid can differ. If the data split is across runs, one assumes that the orientation of the hexadirectional signal is stable over multiple runs. This is not an unreasonable assumption given what we know about grid cells. On the other hand, if the split is within runs (odd/even trajectories or first/second half) it is in principle possible to estimate and test for each run separately, which relaxes the assumption of a grid that is stable over longer periods of time (i.e. runs). 3.1 First half of each run In keeping with the GridCAT manual, let’s for now split each run in a first and a second half based on the number of navigation periods. 3.1.1 EV files for FEAT For each regressor, FSL FEAT expects an EV (EV = explanatory variable, i.e. regressor) file with 3-column format for each regressor. Let’s load the modified event file and write out the regressors we will want to use. These are: navigation EV for all timepoints of translational movement in the entire run sine for movement direction for navigation EV to be used as parametric modulator for first half of onsets of navigation EV cosine for movement direction for navigation EV to be used as parametric modulator for first half of onsets of navigation EV feedback EV modeling time points when participants received feedback (entire run) To look at an n-fold periodic signal, the trajectory angle is multiplied by the desired periodicity (e.g. 6 for hexadirectional analysis) before calculating the (co)sine. Thus, there is a pair of parametric modulators for each periodicity you want to check. # we want to look for six-fold signals, other periodicities are controls periodicities &lt;- c(6) for (i_sub in subjects){ for (i_run in runs){ # create directory for EV files ev_dir &lt;- here(&quot;data&quot;, &quot;glm1&quot;, &quot;glm1_firsthalf&quot;, &quot;feat_ev&quot;, i_sub, i_run) if(!dir.exists(ev_dir)){dir.create(ev_dir, recursive = TRUE)} # read the event table file fn &lt;- here(&quot;data&quot;, &quot;EventTables&quot;, i_sub, paste0(&quot;eventTable_&quot;, i_run, &quot;_jb.txt&quot;)) event_table &lt;- read_delim(fn, delim = &quot;\\t&quot;, col_names = TRUE, col_types = c(&quot;fddd&quot;)) # write the navigation (translation) regressor to file in 3-column format for FSL fn &lt;- file.path(ev_dir, &quot;translation.txt&quot;) event_table %&gt;% filter(name==&quot;translation&quot;) %&gt;% select(c(onset, duration)) %&gt;% mutate(weight=1) %&gt;% write_delim(file = fn, delim = &quot;\\t&quot;, col_names = FALSE) # write the feedback regressor to file in 3-column format for FSL fn &lt;- file.path(ev_dir, &quot;feedback.txt&quot;) event_table %&gt;% filter(name==&quot;feedback&quot;) %&gt;% select(c(onset, duration)) %&gt;% mutate(weight=1) %&gt;% write_delim(file = fn, delim = &quot;\\t&quot;, col_names = FALSE) for (i_period in periodicities){ # add sine and cosine of running angle event_table &lt;- event_table %&gt;% # CAVE: transform angles to radians before calculating (co)sine! mutate(sine = sin((i_period * angle)*pi/180), cosine = cos((i_period * angle)*pi/180)) head(event_table, n=10) # write the sine of translation angle regressor to file in 3-column format for FSL for first half of trials fn &lt;- file.path(ev_dir, paste0(&quot;translation_sine_&quot;, i_period, &quot;fold_half1.txt&quot;)) event_table %&gt;% filter(name==&quot;translation&quot;) %&gt;% slice_head(n=nrow(.)/2) %&gt;% # first half select(c(onset, duration, sine)) %&gt;% write_delim(file = fn, delim = &quot;\\t&quot;, col_names = FALSE) # write the cosine of translation angle regressor to file in 3-column format for FSL for first half of trials fn &lt;- file.path(ev_dir, paste0(&quot;translation_cosine_&quot;, i_period, &quot;fold_half1.txt&quot;)) event_table %&gt;% filter(name==&quot;translation&quot;) %&gt;% slice_head(n=nrow(.)/2) %&gt;% # first half select(c(onset, duration, cosine)) %&gt;% write_delim(file = fn, delim = &quot;\\t&quot;, col_names = FALSE) } } } 3.1.2 Set up the GLM using FSL FEAT The text below is based on clicking through the FEAT GUI for one run and copying the content of the resulting fsf-file to the chunk below. In this text, we replace lines/variables that need to be altered for each subject with a placeholder. These can then easily be filled in for each run of each subject. The chunk below could be shortened by removing the lines that are irrelevant for GLM 1, e.g. preprocessing, which is not carried out here. dsgn &lt;- &#39; # FEAT version number set fmri(version) 6.00 # Are we in MELODIC? set fmri(inmelodic) 0 # Analysis level # 1 : First-level analysis # 2 : Higher-level analysis set fmri(level) 1 # Which stages to run # 0 : No first-level analysis (registration and/or group stats only) # 7 : Full first-level analysis # 1 : Pre-processing # 2 : Statistics set fmri(analysis) 2 # Use relative filenames set fmri(relative_yn) 0 # Balloon help set fmri(help_yn) 1 # Run Featwatcher set fmri(featwatcher_yn) 1 # Cleanup first-level standard-space images set fmri(sscleanup_yn) 0 # Output directory set fmri(outputdir) &quot;@out_dir@&quot; # TR(s) set fmri(tr) @tr@ # Total volumes set fmri(npts) @n_vols@ # Delete volumes set fmri(ndelete) 0 # Perfusion tag/control order set fmri(tagfirst) 1 # Number of first-level analyses set fmri(multiple) 1 # Higher-level input type # 1 : Inputs are lower-level FEAT directories # 2 : Inputs are cope images from FEAT directories set fmri(inputtype) 2 # Carry out pre-stats processing? set fmri(filtering_yn) 0 # Brain/background threshold, % set fmri(brain_thresh) 10 # Critical z for design efficiency calculation set fmri(critical_z) 5.3 # Noise level set fmri(noise) 0.66 # Noise AR(1) set fmri(noisear) 0.34 # Motion correction # 0 : None # 1 : MCFLIRT set fmri(mc) 1 # Spin-history (currently obsolete) set fmri(sh_yn) 0 # B0 fieldmap unwarping? set fmri(regunwarp_yn) 0 # GDC Test set fmri(gdc) &quot;&quot; # EPI dwell time (ms) set fmri(dwell) 0.7 # EPI TE (ms) set fmri(te) 35 # % Signal loss threshold set fmri(signallossthresh) 10 # Unwarp direction set fmri(unwarp_dir) y- # Slice timing correction # 0 : None # 1 : Regular up (0, 1, 2, 3, ...) # 2 : Regular down # 3 : Use slice order file # 4 : Use slice timings file # 5 : Interleaved (0, 2, 4 ... 1, 3, 5 ... ) set fmri(st) 0 # Slice timings file set fmri(st_file) &quot;&quot; # BET brain extraction set fmri(bet_yn) 1 # Spatial smoothing FWHM (mm) set fmri(smooth) 5 # Intensity normalization set fmri(norm_yn) 0 # Perfusion subtraction set fmri(perfsub_yn) 0 # Highpass temporal filtering set fmri(temphp_yn) 1 # Lowpass temporal filtering set fmri(templp_yn) 0 # MELODIC ICA data exploration set fmri(melodic_yn) 0 # Carry out main stats? set fmri(stats_yn) 1 # Carry out prewhitening? set fmri(prewhiten_yn) 1 # Add motion parameters to model # 0 : No # 1 : Yes set fmri(motionevs) 0 set fmri(motionevsbeta) &quot;&quot; set fmri(scriptevsbeta) &quot;&quot; # Robust outlier detection in FLAME? set fmri(robust_yn) 0 # Higher-level modelling # 3 : Fixed effects # 0 : Mixed Effects: Simple OLS # 2 : Mixed Effects: FLAME 1 # 1 : Mixed Effects: FLAME 1+2 set fmri(mixed_yn) 2 # Higher-level permutations set fmri(randomisePermutations) 5000 # Number of EVs set fmri(evs_orig) 4 set fmri(evs_real) 8 set fmri(evs_vox) 0 # Number of contrasts set fmri(ncon_orig) 3 set fmri(ncon_real) 3 # Number of F-tests set fmri(nftests_orig) 1 set fmri(nftests_real) 1 # Add constant column to design matrix? (obsolete) set fmri(constcol) 0 # Carry out post-stats steps? set fmri(poststats_yn) 0 # Pre-threshold masking? set fmri(threshmask) &quot;&quot; # Thresholding # 0 : None # 1 : Uncorrected # 2 : Voxel # 3 : Cluster set fmri(thresh) 3 # P threshold set fmri(prob_thresh) 0.05 # Z threshold set fmri(z_thresh) 3.1 # Z min/max for colour rendering # 0 : Use actual Z min/max # 1 : Use preset Z min/max set fmri(zdisplay) 0 # Z min in colour rendering set fmri(zmin) 2 # Z max in colour rendering set fmri(zmax) 8 # Colour rendering type # 0 : Solid blobs # 1 : Transparent blobs set fmri(rendertype) 1 # Background image for higher-level stats overlays # 1 : Mean highres # 2 : First highres # 3 : Mean functional # 4 : First functional # 5 : Standard space template set fmri(bgimage) 1 # Create time series plots set fmri(tsplot_yn) 1 # Registration to initial structural set fmri(reginitial_highres_yn) 0 # Search space for registration to initial structural # 0 : No search # 90 : Normal search # 180 : Full search set fmri(reginitial_highres_search) 90 # Degrees of Freedom for registration to initial structural set fmri(reginitial_highres_dof) 3 # Registration to main structural set fmri(reghighres_yn) 0 # Search space for registration to main structural # 0 : No search # 90 : Normal search # 180 : Full search set fmri(reghighres_search) 90 # Degrees of Freedom for registration to main structural set fmri(reghighres_dof) BBR # Registration to standard image? set fmri(regstandard_yn) 1 # Use alternate reference images? set fmri(alternateReference_yn) 0 # Standard image set fmri(regstandard) &quot;/usr/local/fsl/data/standard/MNI152_T1_2mm_brain&quot; # Search space for registration to standard space # 0 : No search # 90 : Normal search # 180 : Full search set fmri(regstandard_search) 90 # Degrees of Freedom for registration to standard space set fmri(regstandard_dof) 3 # Do nonlinear registration from structural to standard space? set fmri(regstandard_nonlinear_yn) 0 # Control nonlinear warp field resolution set fmri(regstandard_nonlinear_warpres) 10 # High pass filter cutoff set fmri(paradigm_hp) 100 # Total voxels set fmri(totalVoxels) 179159040 # Number of lower-level copes feeding into higher-level analysis set fmri(ncopeinputs) 0 # 4D AVW data or FEAT directory (1) set feat_files(1) &quot;@func_fn@&quot; # Add confound EVs text file set fmri(confoundevs) 1 # Confound EVs text file for analysis 1 set confoundev_files(1) &quot;@conf_ev_fn@&quot; # EV 1 title set fmri(evtitle1) &quot;navigation&quot; # Basic waveform shape (EV 1) # 0 : Square # 1 : Sinusoid # 2 : Custom (1 entry per volume) # 3 : Custom (3 column format) # 4 : Interaction # 10 : Empty (all zeros) set fmri(shape1) 3 # Convolution (EV 1) # 0 : None # 1 : Gaussian # 2 : Gamma # 3 : Double-Gamma HRF # 4 : Gamma basis functions # 5 : Sine basis functions # 6 : FIR basis functions # 8 : Alternate Double-Gamma set fmri(convolve1) 2 # Convolve phase (EV 1) set fmri(convolve_phase1) 0 # Apply temporal filtering (EV 1) set fmri(tempfilt_yn1) 1 # Add temporal derivative (EV 1) set fmri(deriv_yn1) 1 # Custom EV file (EV 1) set fmri(custom1) &quot;@navi_ev_fn@&quot; # Gamma sigma (EV 1) set fmri(gammasigma1) 3 # Gamma delay (EV 1) set fmri(gammadelay1) 6 # Orthogonalise EV 1 wrt EV 0 set fmri(ortho1.0) 0 # Orthogonalise EV 1 wrt EV 1 set fmri(ortho1.1) 0 # Orthogonalise EV 1 wrt EV 2 set fmri(ortho1.2) 0 # Orthogonalise EV 1 wrt EV 3 set fmri(ortho1.3) 0 # Orthogonalise EV 1 wrt EV 4 set fmri(ortho1.4) 0 # EV 2 title set fmri(evtitle2) &quot;sine&quot; # Basic waveform shape (EV 2) # 0 : Square # 1 : Sinusoid # 2 : Custom (1 entry per volume) # 3 : Custom (3 column format) # 4 : Interaction # 10 : Empty (all zeros) set fmri(shape2) 3 # Convolution (EV 2) # 0 : None # 1 : Gaussian # 2 : Gamma # 3 : Double-Gamma HRF # 4 : Gamma basis functions # 5 : Sine basis functions # 6 : FIR basis functions # 8 : Alternate Double-Gamma set fmri(convolve2) 2 # Convolve phase (EV 2) set fmri(convolve_phase2) 0 # Apply temporal filtering (EV 2) set fmri(tempfilt_yn2) 1 # Add temporal derivative (EV 2) set fmri(deriv_yn2) 1 # Custom EV file (EV 2) set fmri(custom2) &quot;@sine_ev_fn@&quot; # Gamma sigma (EV 2) set fmri(gammasigma2) 3 # Gamma delay (EV 2) set fmri(gammadelay2) 6 # Orthogonalise EV 2 wrt EV 0 set fmri(ortho2.0) 0 # Orthogonalise EV 2 wrt EV 1 set fmri(ortho2.1) 0 # Orthogonalise EV 2 wrt EV 2 set fmri(ortho2.2) 0 # Orthogonalise EV 2 wrt EV 3 set fmri(ortho2.3) 0 # Orthogonalise EV 2 wrt EV 4 set fmri(ortho2.4) 0 # EV 3 title set fmri(evtitle3) &quot;cosine&quot; # Basic waveform shape (EV 3) # 0 : Square # 1 : Sinusoid # 2 : Custom (1 entry per volume) # 3 : Custom (3 column format) # 4 : Interaction # 10 : Empty (all zeros) set fmri(shape3) 3 # Convolution (EV 3) # 0 : None # 1 : Gaussian # 2 : Gamma # 3 : Double-Gamma HRF # 4 : Gamma basis functions # 5 : Sine basis functions # 6 : FIR basis functions # 8 : Alternate Double-Gamma set fmri(convolve3) 2 # Convolve phase (EV 3) set fmri(convolve_phase3) 0 # Apply temporal filtering (EV 3) set fmri(tempfilt_yn3) 1 # Add temporal derivative (EV 3) set fmri(deriv_yn3) 1 # Custom EV file (EV 3) set fmri(custom3) &quot;@cosine_ev_fn@&quot; # Gamma sigma (EV 3) set fmri(gammasigma3) 3 # Gamma delay (EV 3) set fmri(gammadelay3) 6 # Orthogonalise EV 3 wrt EV 0 set fmri(ortho3.0) 0 # Orthogonalise EV 3 wrt EV 1 set fmri(ortho3.1) 0 # Orthogonalise EV 3 wrt EV 2 set fmri(ortho3.2) 0 # Orthogonalise EV 3 wrt EV 3 set fmri(ortho3.3) 0 # Orthogonalise EV 3 wrt EV 4 set fmri(ortho3.4) 0 # EV 4 title set fmri(evtitle4) &quot;feedback&quot; # Basic waveform shape (EV 4) # 0 : Square # 1 : Sinusoid # 2 : Custom (1 entry per volume) # 3 : Custom (3 column format) # 4 : Interaction # 10 : Empty (all zeros) set fmri(shape4) 3 # Convolution (EV 4) # 0 : None # 1 : Gaussian # 2 : Gamma # 3 : Double-Gamma HRF # 4 : Gamma basis functions # 5 : Sine basis functions # 6 : FIR basis functions # 8 : Alternate Double-Gamma set fmri(convolve4) 2 # Convolve phase (EV 4) set fmri(convolve_phase4) 0 # Apply temporal filtering (EV 4) set fmri(tempfilt_yn4) 1 # Add temporal derivative (EV 4) set fmri(deriv_yn4) 1 # Custom EV file (EV 4) set fmri(custom4) &quot;@feedback_ev_fn@&quot; # Gamma sigma (EV 4) set fmri(gammasigma4) 3 # Gamma delay (EV 4) set fmri(gammadelay4) 6 # Orthogonalise EV 4 wrt EV 0 set fmri(ortho4.0) 0 # Orthogonalise EV 4 wrt EV 1 set fmri(ortho4.1) 0 # Orthogonalise EV 4 wrt EV 2 set fmri(ortho4.2) 0 # Orthogonalise EV 4 wrt EV 3 set fmri(ortho4.3) 0 # Orthogonalise EV 4 wrt EV 4 set fmri(ortho4.4) 0 # Contrast &amp; F-tests mode # real : control real EVs # orig : control original EVs set fmri(con_mode_old) orig set fmri(con_mode) orig # Display images for contrast_real 1 set fmri(conpic_real.1) 1 # Title for contrast_real 1 set fmri(conname_real.1) &quot;navigation vs. baseline&quot; # Real contrast_real vector 1 element 1 set fmri(con_real1.1) 1 # Real contrast_real vector 1 element 2 set fmri(con_real1.2) 0 # Real contrast_real vector 1 element 3 set fmri(con_real1.3) 0 # Real contrast_real vector 1 element 4 set fmri(con_real1.4) 0 # Real contrast_real vector 1 element 5 set fmri(con_real1.5) 0 # Real contrast_real vector 1 element 6 set fmri(con_real1.6) 0 # Real contrast_real vector 1 element 7 set fmri(con_real1.7) 0 # Real contrast_real vector 1 element 8 set fmri(con_real1.8) 0 # F-test 1 element 1 set fmri(ftest_real1.1) 0 # Display images for contrast_real 2 set fmri(conpic_real.2) 1 # Title for contrast_real 2 set fmri(conname_real.2) &quot;sine vs. 0&quot; # Real contrast_real vector 2 element 1 set fmri(con_real2.1) 0 # Real contrast_real vector 2 element 2 set fmri(con_real2.2) 0 # Real contrast_real vector 2 element 3 set fmri(con_real2.3) 1.0 # Real contrast_real vector 2 element 4 set fmri(con_real2.4) 0 # Real contrast_real vector 2 element 5 set fmri(con_real2.5) 0 # Real contrast_real vector 2 element 6 set fmri(con_real2.6) 0 # Real contrast_real vector 2 element 7 set fmri(con_real2.7) 0 # Real contrast_real vector 2 element 8 set fmri(con_real2.8) 0 # F-test 1 element 2 set fmri(ftest_real1.2) 1 # Display images for contrast_real 3 set fmri(conpic_real.3) 1 # Title for contrast_real 3 set fmri(conname_real.3) &quot;cosine vs. 0&quot; # Real contrast_real vector 3 element 1 set fmri(con_real3.1) 0 # Real contrast_real vector 3 element 2 set fmri(con_real3.2) 0 # Real contrast_real vector 3 element 3 set fmri(con_real3.3) 0 # Real contrast_real vector 3 element 4 set fmri(con_real3.4) 0 # Real contrast_real vector 3 element 5 set fmri(con_real3.5) 1.0 # Real contrast_real vector 3 element 6 set fmri(con_real3.6) 0 # Real contrast_real vector 3 element 7 set fmri(con_real3.7) 0 # Real contrast_real vector 3 element 8 set fmri(con_real3.8) 0 # F-test 1 element 3 set fmri(ftest_real1.3) 1 # Display images for contrast_orig 1 set fmri(conpic_orig.1) 1 # Title for contrast_orig 1 set fmri(conname_orig.1) &quot;navigation vs. baseline&quot; # Real contrast_orig vector 1 element 1 set fmri(con_orig1.1) 1 # Real contrast_orig vector 1 element 2 set fmri(con_orig1.2) 0 # Real contrast_orig vector 1 element 3 set fmri(con_orig1.3) 0 # Real contrast_orig vector 1 element 4 set fmri(con_orig1.4) 0 # F-test 1 element 1 set fmri(ftest_orig1.1) 0 # Display images for contrast_orig 2 set fmri(conpic_orig.2) 1 # Title for contrast_orig 2 set fmri(conname_orig.2) &quot;sine vs. 0&quot; # Real contrast_orig vector 2 element 1 set fmri(con_orig2.1) 0 # Real contrast_orig vector 2 element 2 set fmri(con_orig2.2) 1.0 # Real contrast_orig vector 2 element 3 set fmri(con_orig2.3) 0 # Real contrast_orig vector 2 element 4 set fmri(con_orig2.4) 0 # F-test 1 element 2 set fmri(ftest_orig1.2) 1 # Display images for contrast_orig 3 set fmri(conpic_orig.3) 1 # Title for contrast_orig 3 set fmri(conname_orig.3) &quot;cosine vs. 0&quot; # Real contrast_orig vector 3 element 1 set fmri(con_orig3.1) 0 # Real contrast_orig vector 3 element 2 set fmri(con_orig3.2) 0 # Real contrast_orig vector 3 element 3 set fmri(con_orig3.3) 1.0 # Real contrast_orig vector 3 element 4 set fmri(con_orig3.4) 0 # F-test 1 element 3 set fmri(ftest_orig1.3) 1 # Contrast masking - use &gt;0 instead of thresholding? set fmri(conmask_zerothresh_yn) 0 # Mask real contrast/F-test 1 with real contrast/F-test 2? set fmri(conmask1_2) 0 # Mask real contrast/F-test 1 with real contrast/F-test 3? set fmri(conmask1_3) 0 # Mask real contrast/F-test 1 with real contrast/F-test 4? set fmri(conmask1_4) 0 # Mask real contrast/F-test 2 with real contrast/F-test 1? set fmri(conmask2_1) 0 # Mask real contrast/F-test 2 with real contrast/F-test 3? set fmri(conmask2_3) 0 # Mask real contrast/F-test 2 with real contrast/F-test 4? set fmri(conmask2_4) 0 # Mask real contrast/F-test 3 with real contrast/F-test 1? set fmri(conmask3_1) 0 # Mask real contrast/F-test 3 with real contrast/F-test 2? set fmri(conmask3_2) 0 # Mask real contrast/F-test 3 with real contrast/F-test 4? set fmri(conmask3_4) 0 # Mask real contrast/F-test 4 with real contrast/F-test 1? set fmri(conmask4_1) 0 # Mask real contrast/F-test 4 with real contrast/F-test 2? set fmri(conmask4_2) 0 # Mask real contrast/F-test 4 with real contrast/F-test 3? set fmri(conmask4_3) 0 # Do contrast masking at all? set fmri(conmask1_1) 0 ########################################################## # Now options that do not appear in the GUI # Alternative (to BETting) mask image set fmri(alternative_mask) &quot;&quot; # Initial structural space registration initialisation transform set fmri(init_initial_highres) &quot;&quot; # Structural space registration initialisation transform set fmri(init_highres) &quot;&quot; # Standard space registration initialisation transform set fmri(init_standard) &quot;&quot; # For full FEAT analysis: overwrite existing .feat output dir? set fmri(overwrite_yn) 0 &#39; Now, we define the function that creates the fsf-file by filling the placeholders and writing to file. create_fsf &lt;- function(fsf = dsgn, placeholder = c(&quot;@n_vols@&quot;), replace_with = c(&quot;666&quot;), out_fn = NA){ assertthat::are_equal(length(placeholder), length(replace_with)) # loop over the placeholders and fill them with info for (i in 1:length(placeholder)){ fsf &lt;- gsub(pattern=placeholder[i], replacement = replace_with[i], x=fsf) } # write fsf file con&lt;-file(out_fn) writeLines(fsf, con) close(con) } Next, for each run and periodicity, let’s replace the placeholders with the required variables. # these are the placeholders in the fsf to_replace &lt;- c(&quot;@out_dir@&quot;, &quot;@func_fn@&quot;, &quot;@tr@&quot;, &quot;@n_vols@&quot;, &quot;@navi_ev_fn@&quot;, &quot;@sine_ev_fn@&quot;, &quot;@cosine_ev_fn@&quot;, &quot;@feedback_ev_fn@&quot;, &quot;@conf_ev_fn@&quot;) for (i_sub in subjects){ for (i_run in runs){ # current functional data and find number of volumes in case they differ func_fn &lt;- here(&quot;data&quot;, &quot;FunctionalScans&quot;, &quot;4D&quot;, i_sub, i_run, paste0(i_run, &quot;_masked.nii.gz&quot;)) hdr &lt;- fslhd(func_fn, verbose =FALSE) hdr &lt;- hdr[grep(&quot;\\\\bdim4\\\\b&quot;, hdr)] n_vols &lt;- regmatches(hdr, gregexpr(&quot;[[:digit:]]+&quot;, hdr))[[1]][2] for (i_period in periodicities){ # folder to write the fsf-files to fsf_dir &lt;- here(&quot;data&quot;, &quot;glm1&quot;, &quot;glm1_firsthalf&quot;, &quot;feat_design&quot;, paste0(i_period, &quot;fold&quot;), i_sub, i_run) if(!dir.exists(fsf_dir)){dir.create(fsf_dir, recursive = TRUE)} # collect the info we need fsf_fn &lt;- file.path(fsf_dir, sprintf(&quot;%s_%s_%dfold.fsf&quot;, i_sub, i_run, i_period)) out_dir &lt;- here(&quot;data&quot;, &quot;glm1&quot;, &quot;glm1_firsthalf&quot;, paste0(i_period, &quot;fold&quot;), i_sub, i_run) tr &lt;- 1.5 navi_ev_fn &lt;- here(&quot;data&quot;, &quot;glm1&quot;, &quot;glm1_firsthalf&quot;, &quot;feat_ev&quot;, i_sub, i_run, &quot;translation.txt&quot;) sine_ev_fn &lt;- here(&quot;data&quot;, &quot;glm1&quot;, &quot;glm1_firsthalf&quot;, &quot;feat_ev&quot;, i_sub, i_run, paste0(&quot;translation_sine_&quot;, i_period, &quot;fold_half1.txt&quot;)) cosine_ev_fn &lt;- here(&quot;data&quot;, &quot;glm1&quot;, &quot;glm1_firsthalf&quot;, &quot;feat_ev&quot;, i_sub, i_run, paste0(&quot;translation_cosine_&quot;, i_period, &quot;fold_half1.txt&quot;)) feedback_ev_fn &lt;- here(&quot;data&quot;, &quot;glm1&quot;, &quot;glm1_firsthalf&quot;, &quot;feat_ev&quot;, i_sub, i_run, &quot;feedback.txt&quot;) conf_ev_fn &lt;- here(&quot;data&quot;, &quot;AdditionalRegressors&quot;, i_sub, paste0(&quot;realignmentParameters_&quot;, i_run ,&quot;.txt&quot;)) # collect the filler items. CAVE: Must be in same order as to_replace fillers &lt;- c(out_dir, func_fn, tr, n_vols, navi_ev_fn, sine_ev_fn, cosine_ev_fn, feedback_ev_fn, conf_ev_fn) # create the fsf file create_fsf(fsf = dsgn, placeholder = to_replace, replace_with = fillers, out_fn = fsf_fn) # create GLM design files to use with film_gls system(sprintf(&quot;%s/bin/feat_model %s %s&quot;, fsldir(), tools::file_path_sans_ext(fsf_fn), conf_ev_fn)) } } } 3.1.3 Run GLM1 We are ready to run GLM1. We can do so using FEAT or the bare film_gls command. NB: For this to work, make sure FSL is correctly configured. On MacOS that might mean starting RStudio from the terminal (open -na Rstudio). 3.1.3.1 FEAT We start by running GLM1 using FEAT. for (i_sub in subjects){ for (i_run in runs){ for (i_period in periodicities){ # check if the zstat of the F-contrast exists, this should be one of the last files written fn &lt;- here(&quot;data&quot;, &quot;glm1&quot;, &quot;glm1_firsthalf&quot;, paste0(i_period, &quot;fold&quot;), i_sub, paste0(i_run, &quot;.feat&quot;), &quot;stats&quot;, &quot;zfstat1.nii.gz&quot;) if (!file.exists(fn)){ # build the command and run fsf_fn &lt;- here(&quot;data&quot;, &quot;glm1&quot;, &quot;glm1_firsthalf&quot;, &quot;feat_design&quot;, paste0(i_period, &quot;fold&quot;), i_sub, i_run, sprintf(&quot;%s_%s_%dfold.fsf&quot;, i_sub, i_run, i_period)) cmd &lt;- sprintf(&quot;%s/bin/feat %s&quot;, fsldir(), fsf_fn) system(cmd, intern = TRUE) # remove the residuals file to clear some space system(sprintf(&quot;rm %s&quot;, here(&quot;data&quot;, &quot;glm1&quot;, &quot;glm1_firsthalf&quot;, paste0(i_period, &quot;fold&quot;), i_sub, paste0(i_run, &quot;.feat&quot;), &quot;stats&quot;, &quot;res4d.nii.gz&quot;))) } } } } Here is the design matrix as visualized by FEAT: GLM1 design matrix Covariance matrix &amp; design efficiency: 3.1.3.2 FILM_GLS The command here is based on the command used by FEAT. The results should thus be identical. for (i_sub in subjects){ for (i_run in runs){ for (i_period in periodicities){ # files and folders to be used as input for film_gls func_fn &lt;- here(&quot;data&quot;, &quot;FunctionalScans&quot;, &quot;4D&quot;, i_sub, i_run, paste0(i_run, &quot;_masked.nii.gz&quot;)) out_dir &lt;- here(&quot;data&quot;, &quot;glm1&quot;, &quot;glm1_firsthalf&quot;, paste0(i_period, &quot;fold&quot;), i_sub, i_run) pd_fn &lt;- here(&quot;data&quot;, &quot;glm1&quot;, &quot;glm1_firsthalf&quot;, &quot;feat_design&quot;, paste0(i_period, &quot;fold&quot;), i_sub, i_run, sprintf(&quot;%s_%s_%dfold.mat&quot;, i_sub, i_run, i_period)) con_fn &lt;- here(&quot;data&quot;, &quot;glm1&quot;, &quot;glm1_firsthalf&quot;, &quot;feat_design&quot;, paste0(i_period, &quot;fold&quot;), i_sub, i_run, sprintf(&quot;%s_%s_%dfold.con&quot;, i_sub, i_run, i_period)) fcon_fn &lt;- here(&quot;data&quot;, &quot;glm1&quot;, &quot;glm1_firsthalf&quot;, &quot;feat_design&quot;, paste0(i_period, &quot;fold&quot;), i_sub, i_run, sprintf(&quot;%s_%s_%dfold.fts&quot;, i_sub, i_run, i_period)) # check if the zstat of the F-contrast exists, this should be one of the last files written fn &lt;- file.path(out_dir, &quot;zfstat1.nii.gz&quot;) if (!file.exists(fn)){ # build the command and run cmd &lt;- sprintf(&quot;%s/bin/film_gls --in=%s --rn=%s --pd=%s --thr=61 --sa --ms=5 --con=%s --fcon=%s&quot;, fsldir(), func_fn, out_dir, pd_fn, con_fn, fcon_fn) system(cmd) # remove the residuals file to clear some space system(sprintf(&quot;rm %s&quot;, file.path(out_dir, &quot;res4d.nii.gz&quot;))) } } } } 3.1.4 Results GLM 1 3.1.4.1 Compare results from FEAT and FILM After running the analysis using FEAT and via film_gls directly, let’s check if the results are comparable. We simply load the images with the results of the F-Test of the periodic sine and cosine regressors and correlate the F-values across voxels. for (i_sub in subjects){ for (i_run in runs){ for (i_period in periodicities){ # load the F-Stat images fn1 &lt;- here(&quot;data&quot;, &quot;glm1&quot;, &quot;glm1_firsthalf&quot;, paste0(i_period, &quot;fold&quot;), i_sub, paste0(i_run, &quot;.feat&quot;), &quot;stats&quot;, &quot;fstat1.nii.gz&quot;) fn2 &lt;- here(&quot;data&quot;, &quot;glm1&quot;, &quot;glm1_firsthalf&quot;, paste0(i_period, &quot;fold&quot;), i_sub, i_run, &quot;fstat1.nii.gz&quot;) feat_nii &lt;- readNIfTI2(fn1) film_nii &lt;- readNIfTI2(fn2) # store in data frame stat_df &lt;- tibble(feat = c(feat_nii), film = c(film_nii)) # diagnostic plot p1 &lt;- ggplot(stat_df, aes(x=feat, y=film)) + geom_point() + theme_cowplot() + theme(aspect.ratio = 1) + labs(title = &quot;F-Statistics from FEAT and FILM&quot;, subtitle = sprintf(&quot;%s, %s, %d-fold: r=%.3f&quot;, i_sub, i_run, i_period, cor(stat_df$feat, stat_df$film))) print(p1) } } } 3.1.4.2 F-Test results Finally, we can plot the F-Test results onto the brain. This F-test is not unbiased, but is often used prominently in papers (c.f. Constantinescu et al., Science, 2016; Bongioanni et al., Nature, 2021). It is not the cross-validated (i.e. tested on an independent data partition), but Bongioanni et al. (Nature, 2021) developed a permutation-based test to use it for significance testing. Using the F-Test on periodic sine and cosine regressors fitted to the entire dataset might be the most powerful approach to demonstrate a hexadirectional signal. The plots below are arbitrarily thresholded at F &gt; 2. for (i_sub in subjects){ for (i_run in runs){ for (i_period in periodicities){ # load the mean functional and F-Stat image fn &lt;- here(&quot;data&quot;, &quot;glm1&quot;, &quot;glm1_firsthalf&quot;, paste0(i_period, &quot;fold&quot;), i_sub, paste0(i_run, &quot;.feat&quot;), &quot;mean_func.nii.gz&quot;) mean_func_nii &lt;- readNIfTI2(fn) fn &lt;- here(&quot;data&quot;, &quot;glm1&quot;, &quot;glm1_firsthalf&quot;, paste0(i_period, &quot;fold&quot;), i_sub, i_run, &quot;fstat1.nii.gz&quot;) f_nii &lt;- readNIfTI2(fn) f_nii[f_nii &lt; 2] &lt;- 0 # overlay F-test on mean func ortho2(mean_func_nii, f_nii, xyz = c(46,46,15), ycolorbar = TRUE, col.y = oro.nifti::hotmetal(10), ybreaks = seq(2,7,0.5)) } } } "],["estimate-orientation.html", "4 Estimate orientation 4.1 Load PEs of parametric modulators 4.2 Compute Voxelwise Orientation 4.3 Average grid orientations 4.4 Brain plot of estimated orientations 4.5 Store estimated grid orientation", " 4 Estimate orientation Based on the parameter estimates for the sine and cosine regressor we will now estimate the orientation of the n-fold symmetric signal. This estimated orientation then forms the basis for GLM2, where we look for signal modulations as a function of angular difference to the estimated orientation. Typically, the orientation is averaged across runs and voxels in a region of interest such as the entorhinal cortex. This is also the approach we will implement here for now. A possible long-term goal is to use the voxelwise orientation for GLM2 for whole-brain/whole-surface analysis. However, I need to better understand how to implement voxelwise regression before I can do this. 4.1 Load PEs of parametric modulators We begin by building a dataframe holding the parameter estimates (PEs) of the sine and cosine regressor for each subject, run and periodicity. pmod_df &lt;- tibble() for (i_sub in subjects){ # load the right EC mask and linearize it ec_mask_nii &lt;- readNIfTI2(here(&quot;data&quot;, &quot;masks&quot;, &quot;ROI_masks&quot;, &quot;ROImask_entorhinalCortex_RH.nii&quot;)) ec_mask_lin &lt;- c(ec_mask_nii) # load the combined brain mask and linearize it brain_mask_nii &lt;- readNIfTI2(here(&quot;data&quot;, &quot;masks&quot;, &quot;brain_mask&quot;, i_sub, &quot;comb_brain_mask_tMean100.nii.gz&quot;)) brain_mask_lin &lt;- as.logical(c(brain_mask_nii)) for (i_run in runs){ for (i_period in periodicities){ # load the sine and cosine parameter estimates # sine and cosine regressors were the second/third regressors and are thus the # third and fifth PEs in the output because of the temporal derivatives sin_fn &lt;- here(&quot;data&quot;, &quot;glm1&quot;, &quot;glm1_firsthalf&quot;, paste0(i_period, &quot;fold&quot;), i_sub, i_run, &quot;pe3.nii.gz&quot;) cos_fn &lt;- here(&quot;data&quot;, &quot;glm1&quot;, &quot;glm1_firsthalf&quot;, paste0(i_period, &quot;fold&quot;), i_sub, i_run, &quot;pe5.nii.gz&quot;) sin_nii &lt;- readNIfTI2(sin_fn) cos_nii &lt;- readNIfTI2(cos_fn) curr_df &lt;- tibble(subID = i_sub, run = i_run, periodicity = i_period, sin = c(sin_nii)[brain_mask_lin], cos = c(cos_nii)[brain_mask_lin], ec = as.logical(ec_mask_lin[brain_mask_lin]), vox_num = which(brain_mask_lin==1)) pmod_df &lt;- rbind(pmod_df, curr_df) } } } 4.2 Compute Voxelwise Orientation We can now compute the orientation for each voxel and periodicity. The resulting dataframe has orientation values in radians and in degrees. Note that these are in a range from 2*pi/periodicity and 360/periodicity, respectively. orient_allvox &lt;- pmod_df %&gt;% mutate( orient_rad = atan2(sin, cos), # estimate orientation in radians (range -pi to pi) orient_rad = ifelse(orient_rad&lt;0, orient_rad+(2*pi), orient_rad), # bring to range 0 to 2*pi orient_rad = orient_rad/periodicity, # divide by periodicity because of n-fold symmetry orient_deg = orient_rad * 180/pi, # convert to degrees amplitude = sqrt((c(cos)*c(cos)) + (c(sin)*c(sin))) # calculate amplitude for later voxel weighting ) head(orient_allvox) ## # A tibble: 6 × 10 ## subID run periodicity sin cos ec vox_num orient_rad orient_deg amplitude ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 sub01 run01 6 6.53 -2.83 FALSE 4802 0.330 18.9 7.12 ## 2 sub01 run01 6 5.82 -2.89 FALSE 4803 0.339 19.4 6.50 ## 3 sub01 run01 6 3.62 -2.45 FALSE 4804 0.361 20.7 4.37 ## 4 sub01 run01 6 1.73 -1.73 FALSE 4805 0.393 22.5 2.45 ## 5 sub01 run01 6 0.808 -1.25 FALSE 4807 0.428 24.5 1.49 ## 6 sub01 run01 6 1.42 -1.16 FALSE 4808 0.376 21.5 1.83 Because we have multiple runs, we might want to estimate a voxel’s orientation based on average across runs of the sine and cosine parameter estimates. ori_df_avg &lt;- orient_allvox %&gt;% group_by(subID, periodicity, vox_num) %&gt;% summarize(sin = mean(sin), cos = mean(cos), ec = unique(ec), .groups = &quot;drop&quot;) %&gt;% add_column(run = &quot;average&quot;, .after = &quot;subID&quot;) %&gt;% mutate( orient_rad = atan2(sin, cos), # estimate orientation in radians (range -pi to pi) orient_rad = ifelse(orient_rad&lt;0, orient_rad+(2*pi), orient_rad), # bring to range 0 to 2*pi orient_rad = orient_rad/periodicity, # divide by periodicity because of n-fold symmetry orient_deg = orient_rad * 180/pi, # convert to degrees amplitude = sqrt((c(cos)*c(cos)) + (c(sin)*c(sin)))) # calculate amplitude for later voxel weighting orient_allvox &lt;- rbind(orient_allvox, ori_df_avg) 4.3 Average grid orientations To average the estimated orientations across voxels, let’s define a custom function. This is similar to the function in the GridCAT toolbox. It is written to be used with pipes, but probably this could be done more elegantly. Usage: in_df is the input data frame with one row per voxel ori_values is the name of the column holding the voxelwise orientations x-fold is the periodicity of the signal you are looking at weighted is an option for an amplitude-weighted average of the orientation. If you want no weighted average, set it to FALSE in_deg is a logical for whether the orientation value columns is in degrees (TRUE) or radians (FALSE) # custom function to average grid orientation across voxels, for usage see text above calc_avg_ori &lt;- function(in_df = NULL, ori_values = NULL, x_fold = &quot;periodicity&quot;, weighted = FALSE, in_deg = TRUE){ # Input checking (pull variables from dataframe etc., could probably be more elegant) ori_values &lt;- in_df %&gt;% pull(ori_values) # returns numeric vector of orientations if(!is.numeric(x_fold)){ # make sure x_fold is one integer x_fold &lt;- in_df %&gt;% pull(x_fold) %&gt;% unique() # if it&#39;s a column, find the unique values if(!length(x_fold == 1)){ # break if there is not one unique value stop(sprintf((&quot;Can&#39;t average over multiple periodicities! Length of x_fold is %d&quot;), length(x_fold)))} } if(weighted == FALSE){weighted &lt;- 1} # if no weighting is desired, all weights = 1 else{weighted &lt;- in_df %&gt;% pull(weighted)} # else get numeric vector of weights # Transform voxelwise orientations from range [0 360/xFoldSymmetry] to [0 360] degrees or [0 2*pi] radians, # in order to enable calculation of subsequent trigonometric functions which expect this range. ori_values360 &lt;- ori_values * x_fold # Transformation from polar to cartesian cordinate system (for weighting) cart_df &lt;- useful::pol2cart(r = weighted, theta = ori_values360, degrees = in_deg) # find the mean across X and across Y separately x_mean = mean(cart_df$x) y_mean = mean(cart_df$y) # Transformation back from cartesian to polar cordinate system out_df &lt;- cart2pol(x=x_mean, y=y_mean, degrees = in_deg) # touch up the output a bit if(in_deg){ out_df &lt;- out_df %&gt;% mutate( avg_ori_deg = theta/x_fold, avg_ori_rad = (theta*pi/180)/x_fold) } else{ out_df &lt;- out_df %&gt;% mutate( avg_ori_rad = theta/x_fold, avg_ori_deg = (theta*180/pi)/x_fold) } # return the df after removing the angle in 360 deg space and the x and y coords out_df &lt;- out_df %&gt;% select(-theta, -x, -y) return(out_df) } 4.3.1 Wholebrain average orientation Let’s first compute the average grid orientation across all voxels. # weighted average orientation across voxels for each participant, run and periodicity avg_orient_weighted &lt;- orient_allvox %&gt;% group_by(subID, run, periodicity) %&gt;% do(calc_avg_ori(in_df = ., ori_values = &quot;orient_deg&quot;, x_fold = &quot;periodicity&quot;, weighted = &quot;amplitude&quot;, in_deg = TRUE)) %&gt;% ungroup() %&gt;% mutate(weighted = &quot;weighted&quot;) # unweighted average orientation across voxels for each participant, run and periodicity avg_orient_unweighted &lt;- orient_allvox %&gt;% group_by(subID, run, periodicity) %&gt;% do(calc_avg_ori(in_df = ., ori_values = &quot;orient_deg&quot;, x_fold = &quot;periodicity&quot;, weighted = FALSE, in_deg = TRUE)) %&gt;% ungroup() %&gt;% mutate(weighted = &quot;unweighted&quot;) # bind the two together avg_orient_allvox &lt;- rbind(avg_orient_weighted, avg_orient_unweighted) head(avg_orient_allvox) ## # A tibble: 6 × 7 ## subID run periodicity r avg_ori_deg avg_ori_rad weighted ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 sub01 average 6 0.285 28.8 0.502 weighted ## 2 sub01 run01 6 0.214 26.6 0.464 weighted ## 3 sub01 run02 6 0.364 30.1 0.525 weighted ## 4 sub01 average 6 0.287 29.4 0.513 unweighted ## 5 sub01 run01 6 0.143 28.6 0.499 unweighted ## 6 sub01 run02 6 0.284 29.8 0.520 unweighted To get an overview of the estimated orientations, let’s plot them as a circular histogram for all brain voxels, together with the weighted and unweighted angular means. # how many bins do we want for the polar histogram? n_bins = 60 # add a variable with the maximum histogram count with the given number of bins # this will be used later to determine the length of the arrow indicating the means avg_orient_allvox &lt;- inner_join(avg_orient_allvox, orient_allvox %&gt;% group_by(subID, run, periodicity) %&gt;% summarise(hcounts = max(hist(orient_deg, plot = FALSE, breaks = n_bins)$counts), .groups=&quot;drop&quot;), by = c(&quot;subID&quot;, &quot;run&quot;, &quot;periodicity&quot;)) # make polar histogram across voxels and highlight (un)weighted mean orientations ggplot(orient_allvox, aes(x=orient_deg)) + coord_polar() + scale_x_continuous(limits = c(0,60)) + geom_freqpoly(bins = 60) + facet_grid(subID ~ run) + labs(title = &quot;Estimated grid orientations [wholebrain]&quot;) + geom_segment(data=avg_orient_allvox, aes(x=avg_ori_deg,xend=avg_ori_deg, y=0, yend=hcounts, group=weighted, color=weighted), arrow=arrow(angle=10,type=&quot;closed&quot;,length=unit(0.3,&quot;cm&quot;))) + labs(color = &quot;mean orientation&quot;) + theme_minimal() + theme(legend.position = &quot;bottom&quot;) ## Warning: Removed 2 row(s) containing missing values (geom_path). 4.3.2 Entorhinal Cortex average orientation Because our first steps here will focus on the right EC (to check results against the GridCAT tutorial), let’s look at the orientations in that ROI. # let&#39;s look at the EC voxels only orient_ec &lt;- orient_allvox %&gt;% filter(ec==TRUE) head(orient_ec) ## # A tibble: 6 × 10 ## subID run periodicity sin cos ec vox_num orient_rad orient_deg amplitude ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 sub01 run01 6 -0.0603 -0.448 TRUE 98647 0.546 31.3 0.453 ## 2 sub01 run01 6 0.113 -0.628 TRUE 98755 0.494 28.3 0.638 ## 3 sub01 run01 6 0.108 -0.440 TRUE 98756 0.483 27.7 0.453 ## 4 sub01 run01 6 0.214 -0.748 TRUE 98971 0.477 27.3 0.778 ## 5 sub01 run01 6 0.416 -0.841 TRUE 98972 0.447 25.6 0.938 ## 6 sub01 run01 6 0.0366 -0.550 TRUE 99079 0.513 29.4 0.551 We first compute the average grid orientation across all EC voxels. # weighted average orientation across voxels for each participant, run and periodicity avg_orient_weighted &lt;- orient_ec %&gt;% group_by(subID, run, periodicity) %&gt;% do(calc_avg_ori(in_df = ., ori_values = &quot;orient_deg&quot;, x_fold = &quot;periodicity&quot;, weighted = &quot;amplitude&quot;, in_deg = TRUE)) %&gt;% ungroup() %&gt;% mutate(weighted = &quot;weighted&quot;) # unweighted average orientation across voxels for each participant, run and periodicity avg_orient_unweighted &lt;- orient_ec %&gt;% group_by(subID, run, periodicity) %&gt;% do(calc_avg_ori(in_df = ., ori_values = &quot;orient_deg&quot;, x_fold = &quot;periodicity&quot;, weighted = FALSE, in_deg = TRUE)) %&gt;% ungroup() %&gt;% mutate(weighted = &quot;unweighted&quot;) # bind the two together avg_orient_ec &lt;- rbind(avg_orient_weighted, avg_orient_unweighted) head(avg_orient_ec) ## # A tibble: 6 × 7 ## subID run periodicity r avg_ori_deg avg_ori_rad weighted ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 sub01 average 6 0.220 29.3 0.512 weighted ## 2 sub01 run01 6 0.331 25.3 0.442 weighted ## 3 sub01 run02 6 0.193 36.7 0.641 weighted ## 4 sub01 average 6 0.348 30.6 0.535 unweighted ## 5 sub01 run01 6 0.363 28.0 0.488 unweighted ## 6 sub01 run02 6 0.291 36.2 0.632 unweighted To get an overview of the estimated orientations, let’s plot them as a circular histogram for all entorhinal cortex voxels, together with the weighted and unweighted angular means. # how many bins do we want for the polar histogram? n_bins = 60 # add a variable with the maximum histogram count with the given number of bins # this will be used later to determine the length of the arrow indicating the means avg_orient_ec &lt;- inner_join(avg_orient_ec, orient_ec %&gt;% group_by(subID, run, periodicity) %&gt;% summarise(hcounts = max(hist(orient_deg, plot = FALSE, breaks = n_bins)$counts), .groups=&quot;drop&quot;), by = c(&quot;subID&quot;, &quot;run&quot;, &quot;periodicity&quot;)) # make polar histogram across voxels and highlight (un)weighted mean orientations ggplot(orient_ec, aes(x=orient_deg)) + coord_polar() + scale_x_continuous(limits = c(0,60)) + geom_freqpoly(bins = 60) + facet_grid(subID ~ run) + labs(title = &quot;Estimated grid orientations [entorhinal cortex]&quot;) + geom_segment(data=avg_orient_ec, aes(x=avg_ori_deg,xend=avg_ori_deg, y=0, yend=hcounts, group=weighted, color=weighted), arrow=arrow(angle=10,type=&quot;closed&quot;,length=unit(0.3,&quot;cm&quot;))) + labs(color = &quot;mean orientation&quot;) + theme_minimal() + theme(legend.position = &quot;bottom&quot;) ## Warning: Removed 2 row(s) containing missing values (geom_path). 4.4 Brain plot of estimated orientations The computations above have been done for each voxel in the entire brain. To see how estimated orientations are distributed throughout the brain, let’s plot the orientation for each voxel. As our brain mask is not very precise, this is not a very good plot, but serves as a proof-of-principle. # initialize a nifti object for the orientation values orient_nii &lt;- brain_mask_nii # for the voxels in the brain mask, set the values to the orientation values based on the average across run orient_nii[brain_mask_nii==1] &lt;- orient_allvox %&gt;% filter(run==&quot;average&quot;) %&gt;% pull(orient_deg) # overlay of estimated orientation ortho2(brain_mask_nii, orient_nii, xyz = c(46,46,15), ycolorbar = TRUE, col.y = oro.nifti::hotmetal(60), ybreaks = seq(0,60,1)) 4.5 Store estimated grid orientation Calculating GLM 2 requires one reference grid orientation. This could be one separate one per run, but for now, let’s go with the orientation resulting from the average across runs. We pick the amplitude-weighte values. fn &lt;- here(&quot;data&quot;, &quot;glm1&quot;, &quot;glm1_firsthalf&quot;, &quot;avg_orient_ec.txt&quot;) avg_orient_ec %&gt;% filter(run==&quot;average&quot;, weighted == &quot;weighted&quot;) %&gt;% select(-hcounts) %&gt;% write_delim(file = fn, delim = &quot;\\t&quot;, col_names = TRUE) "],["glm-2.html", "5 GLM 2 5.1 Second half of each run", " 5 GLM 2 GLM 2 aims to quantify responses to navigation events as function of angular difference of the running direction to the orientation estimated based on GLM 1. This can be done using different ways. For now, we will implement the parametric modulation and the aligned vs. misaligned approach. Let’s start by loading the estimated orientation to use as reference fn &lt;- here(&quot;data&quot;, &quot;glm1&quot;, &quot;glm1_firsthalf&quot;, &quot;avg_orient_ec.txt&quot;) ref_orient &lt;- read_delim(file = fn, delim = &quot;\\t&quot;, col_names = TRUE, col_types = c(&quot;fffdddf&quot;)) head(ref_orient) ## # A tibble: 1 × 7 ## subID run periodicity r avg_ori_deg avg_ori_rad weighted ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 sub01 average 6 0.220 29.3 0.512 weighted 5.1 Second half of each run We need to run GLM 2 on a data partition that is independent from the one used to estimate GLM 1. In this example case, this is the second half of each run. 5.1.1 Parametric modulation with cosine regressor 5.1.1.1 EV files for FEAT For each regressor, FSL FEAT expects an EV file with 3-column format for each regressor. Let’s load the modified event file and write out the regressors we will want to use. For the parametric modulation approach these are: navigation EV for all timepoints of translational movement in the entire run feedback EV modulating times participants received feedback (entire run) Cosine of the angular difference between movement direction and estimated orientation to be used as a parametric modulator for the second half of onsets of the navigation EV. To look at an n-fold periodic signal, the angular difference between estimated orientation and the trajectory angle is multiplied by the desired periodicity (e.g. 6 for hexadirectional analysis) before calculating the cosine. # we want to look for six-fold signals, other periodicities are controls periodicities &lt;- c(6) for (i_sub in subjects){ for (i_run in runs){ # create directory for EV files ev_dir &lt;- here(&quot;data&quot;, &quot;glm2&quot;, &quot;glm2_secondhalf&quot;, &quot;cosine_pmod&quot;, &quot;feat_ev&quot;, i_sub, i_run) if(!dir.exists(ev_dir)){dir.create(ev_dir, recursive = TRUE)} # read the event table file fn &lt;- here(&quot;data&quot;, &quot;EventTables&quot;, i_sub, paste0(&quot;eventTable_&quot;, i_run, &quot;_jb.txt&quot;)) event_table &lt;- read_delim(fn, delim = &quot;\\t&quot;, col_names = TRUE, col_types = c(&quot;fddd&quot;)) # write the navigation (translation) regressor to file in 3-column format for FSL fn &lt;- file.path(ev_dir, &quot;translation.txt&quot;) event_table %&gt;% filter(name==&quot;translation&quot;) %&gt;% select(c(onset, duration)) %&gt;% mutate(weight=1) %&gt;% write_delim(file = fn, delim = &quot;\\t&quot;, col_names = FALSE) # write the feedback regressor to file in 3-column format for FSL fn &lt;- file.path(ev_dir, &quot;feedback.txt&quot;) event_table %&gt;% filter(name==&quot;feedback&quot;) %&gt;% select(c(onset, duration)) %&gt;% mutate(weight=1) %&gt;% write_delim(file = fn, delim = &quot;\\t&quot;, col_names = FALSE) for (i_period in periodicities){ # get the relevant reference orientation curr_ref_orient &lt;- ref_orient %&gt;% filter(subID==i_sub, periodicity==i_period) %&gt;% pull(avg_ori_deg) # add cosine of angular difference of running angle and reference orientation event_table &lt;- event_table %&gt;% mutate( ref_orient = curr_ref_orient, # angular difference of running direction and reference orientation (max 180 degrees) ang_diff2ref = if_else(angle - curr_ref_orient &lt; 180, # condition angle - curr_ref_orient, # if condition met 360 - (angle - curr_ref_orient)), # if condition not met # CAVE: transform angles to radians before calculating cosine! cosine = cos(i_period * (ang_diff2ref*pi/180))) head(event_table, n=10) # write the cosine of translation angle regressor to file in 3-column format for 2nd half of trials fn &lt;- file.path(ev_dir, paste0(&quot;translation_cosine_&quot;, i_period, &quot;fold_half2.txt&quot;)) event_table %&gt;% filter(name==&quot;translation&quot;) %&gt;% slice_tail(n=round(nrow(.)/2)) %&gt;% # second half (round up for uneven numbers) select(c(onset, duration, cosine)) %&gt;% write_delim(file = fn, delim = &quot;\\t&quot;, col_names = FALSE) } } } 5.1.2 Set up the GLM using FSL FEAT The text below is based on clicking through the FEAT GUI for one run and copying the content of the resulting fsf-file to the chunk below. In this text, we replace lines/variables that need to be altered for each subject with a placeholder. These can then easily be filled in for each run of each subject. The chunk below could be shortened by removing the lines that are irrelevant for GLM 1, e.g. preprocessing, which is not carried out here. dsgn &lt;- &#39; # FEAT version number set fmri(version) 6.00 # Are we in MELODIC? set fmri(inmelodic) 0 # Analysis level # 1 : First-level analysis # 2 : Higher-level analysis set fmri(level) 1 # Which stages to run # 0 : No first-level analysis (registration and/or group stats only) # 7 : Full first-level analysis # 1 : Pre-processing # 2 : Statistics set fmri(analysis) 2 # Use relative filenames set fmri(relative_yn) 0 # Balloon help set fmri(help_yn) 1 # Run Featwatcher set fmri(featwatcher_yn) 1 # Cleanup first-level standard-space images set fmri(sscleanup_yn) 0 # Output directory set fmri(outputdir) &quot;@out_dir@&quot; # TR(s) set fmri(tr) @tr@ # Total volumes set fmri(npts) @n_vols@ # Delete volumes set fmri(ndelete) 0 # Perfusion tag/control order set fmri(tagfirst) 1 # Number of first-level analyses set fmri(multiple) 1 # Higher-level input type # 1 : Inputs are lower-level FEAT directories # 2 : Inputs are cope images from FEAT directories set fmri(inputtype) 2 # Carry out pre-stats processing? set fmri(filtering_yn) 0 # Brain/background threshold, % set fmri(brain_thresh) 10 # Critical z for design efficiency calculation set fmri(critical_z) 5.3 # Noise level set fmri(noise) 0.66 # Noise AR(1) set fmri(noisear) 0.34 # Motion correction # 0 : None # 1 : MCFLIRT set fmri(mc) 1 # Spin-history (currently obsolete) set fmri(sh_yn) 0 # B0 fieldmap unwarping? set fmri(regunwarp_yn) 0 # GDC Test set fmri(gdc) &quot;&quot; # EPI dwell time (ms) set fmri(dwell) 0.7 # EPI TE (ms) set fmri(te) 35 # % Signal loss threshold set fmri(signallossthresh) 10 # Unwarp direction set fmri(unwarp_dir) y- # Slice timing correction # 0 : None # 1 : Regular up (0, 1, 2, 3, ...) # 2 : Regular down # 3 : Use slice order file # 4 : Use slice timings file # 5 : Interleaved (0, 2, 4 ... 1, 3, 5 ... ) set fmri(st) 0 # Slice timings file set fmri(st_file) &quot;&quot; # BET brain extraction set fmri(bet_yn) 1 # Spatial smoothing FWHM (mm) set fmri(smooth) 5 # Intensity normalization set fmri(norm_yn) 0 # Perfusion subtraction set fmri(perfsub_yn) 0 # Highpass temporal filtering set fmri(temphp_yn) 1 # Lowpass temporal filtering set fmri(templp_yn) 0 # MELODIC ICA data exploration set fmri(melodic_yn) 0 # Carry out main stats? set fmri(stats_yn) 1 # Carry out prewhitening? set fmri(prewhiten_yn) 1 # Add motion parameters to model # 0 : No # 1 : Yes set fmri(motionevs) 0 set fmri(motionevsbeta) &quot;&quot; set fmri(scriptevsbeta) &quot;&quot; # Robust outlier detection in FLAME? set fmri(robust_yn) 0 # Higher-level modelling # 3 : Fixed effects # 0 : Mixed Effects: Simple OLS # 2 : Mixed Effects: FLAME 1 # 1 : Mixed Effects: FLAME 1+2 set fmri(mixed_yn) 2 # Higher-level permutations set fmri(randomisePermutations) 5000 # Number of EVs set fmri(evs_orig) 3 set fmri(evs_real) 6 set fmri(evs_vox) 0 # Number of contrasts set fmri(ncon_orig) 1 set fmri(ncon_real) 1 # Number of F-tests set fmri(nftests_orig) 0 set fmri(nftests_real) 0 # Add constant column to design matrix? (obsolete) set fmri(constcol) 0 # Carry out post-stats steps? set fmri(poststats_yn) 0 # Pre-threshold masking? set fmri(threshmask) &quot;&quot; # Thresholding # 0 : None # 1 : Uncorrected # 2 : Voxel # 3 : Cluster set fmri(thresh) 3 # P threshold set fmri(prob_thresh) 0.05 # Z threshold set fmri(z_thresh) 3.1 # Z min/max for colour rendering # 0 : Use actual Z min/max # 1 : Use preset Z min/max set fmri(zdisplay) 0 # Z min in colour rendering set fmri(zmin) 2 # Z max in colour rendering set fmri(zmax) 8 # Colour rendering type # 0 : Solid blobs # 1 : Transparent blobs set fmri(rendertype) 1 # Background image for higher-level stats overlays # 1 : Mean highres # 2 : First highres # 3 : Mean functional # 4 : First functional # 5 : Standard space template set fmri(bgimage) 1 # Create time series plots set fmri(tsplot_yn) 1 # Registration to initial structural set fmri(reginitial_highres_yn) 0 # Search space for registration to initial structural # 0 : No search # 90 : Normal search # 180 : Full search set fmri(reginitial_highres_search) 90 # Degrees of Freedom for registration to initial structural set fmri(reginitial_highres_dof) 3 # Registration to main structural set fmri(reghighres_yn) 0 # Search space for registration to main structural # 0 : No search # 90 : Normal search # 180 : Full search set fmri(reghighres_search) 90 # Degrees of Freedom for registration to main structural set fmri(reghighres_dof) BBR # Registration to standard image? set fmri(regstandard_yn) 1 # Use alternate reference images? set fmri(alternateReference_yn) 0 # Standard image set fmri(regstandard) &quot;/usr/local/fsl/data/standard/MNI152_T1_2mm_brain&quot; # Search space for registration to standard space # 0 : No search # 90 : Normal search # 180 : Full search set fmri(regstandard_search) 90 # Degrees of Freedom for registration to standard space set fmri(regstandard_dof) 3 # Do nonlinear registration from structural to standard space? set fmri(regstandard_nonlinear_yn) 0 # Control nonlinear warp field resolution set fmri(regstandard_nonlinear_warpres) 10 # High pass filter cutoff set fmri(paradigm_hp) 100 # Total voxels set fmri(totalVoxels) 179159040 # Number of lower-level copes feeding into higher-level analysis set fmri(ncopeinputs) 0 # 4D AVW data or FEAT directory (1) set feat_files(1) &quot;@func_fn@&quot; # Add confound EVs text file set fmri(confoundevs) 1 # Confound EVs text file for analysis 1 set confoundev_files(1) &quot;@conf_ev_fn@&quot; # EV 1 title set fmri(evtitle1) &quot;navigation&quot; # Basic waveform shape (EV 1) # 0 : Square # 1 : Sinusoid # 2 : Custom (1 entry per volume) # 3 : Custom (3 column format) # 4 : Interaction # 10 : Empty (all zeros) set fmri(shape1) 3 # Convolution (EV 1) # 0 : None # 1 : Gaussian # 2 : Gamma # 3 : Double-Gamma HRF # 4 : Gamma basis functions # 5 : Sine basis functions # 6 : FIR basis functions # 8 : Alternate Double-Gamma set fmri(convolve1) 2 # Convolve phase (EV 1) set fmri(convolve_phase1) 0 # Apply temporal filtering (EV 1) set fmri(tempfilt_yn1) 1 # Add temporal derivative (EV 1) set fmri(deriv_yn1) 1 # Custom EV file (EV 1) set fmri(custom1) &quot;@navi_ev_fn@&quot; # Gamma sigma (EV 1) set fmri(gammasigma1) 3 # Gamma delay (EV 1) set fmri(gammadelay1) 6 # Orthogonalise EV 1 wrt EV 0 set fmri(ortho1.0) 0 # Orthogonalise EV 1 wrt EV 1 set fmri(ortho1.1) 0 # Orthogonalise EV 1 wrt EV 2 set fmri(ortho1.2) 0 # Orthogonalise EV 1 wrt EV 3 set fmri(ortho1.3) 0 # EV 2 title set fmri(evtitle2) &quot;cosine_pmod&quot; # Basic waveform shape (EV 2) # 0 : Square # 1 : Sinusoid # 2 : Custom (1 entry per volume) # 3 : Custom (3 column format) # 4 : Interaction # 10 : Empty (all zeros) set fmri(shape2) 3 # Convolution (EV 2) # 0 : None # 1 : Gaussian # 2 : Gamma # 3 : Double-Gamma HRF # 4 : Gamma basis functions # 5 : Sine basis functions # 6 : FIR basis functions # 8 : Alternate Double-Gamma set fmri(convolve2) 2 # Convolve phase (EV 2) set fmri(convolve_phase2) 0 # Apply temporal filtering (EV 2) set fmri(tempfilt_yn2) 1 # Add temporal derivative (EV 2) set fmri(deriv_yn2) 1 # Custom EV file (EV 2) set fmri(custom2) &quot;@cosine_ev_fn@&quot; # Gamma sigma (EV 2) set fmri(gammasigma2) 3 # Gamma delay (EV 2) set fmri(gammadelay2) 6 # Orthogonalise EV 2 wrt EV 0 set fmri(ortho2.0) 0 # Orthogonalise EV 2 wrt EV 1 set fmri(ortho2.1) 0 # Orthogonalise EV 2 wrt EV 2 set fmri(ortho2.2) 0 # Orthogonalise EV 2 wrt EV 3 set fmri(ortho2.3) 0 # EV 3 title set fmri(evtitle3) &quot;feedback&quot; # Basic waveform shape (EV 3) # 0 : Square # 1 : Sinusoid # 2 : Custom (1 entry per volume) # 3 : Custom (3 column format) # 4 : Interaction # 10 : Empty (all zeros) set fmri(shape3) 3 # Convolution (EV 3) # 0 : None # 1 : Gaussian # 2 : Gamma # 3 : Double-Gamma HRF # 4 : Gamma basis functions # 5 : Sine basis functions # 6 : FIR basis functions # 8 : Alternate Double-Gamma set fmri(convolve3) 2 # Convolve phase (EV 3) set fmri(convolve_phase3) 0 # Apply temporal filtering (EV 3) set fmri(tempfilt_yn3) 1 # Add temporal derivative (EV 3) set fmri(deriv_yn3) 1 # Custom EV file (EV 3) set fmri(custom3) &quot;@feedback_ev_fn@&quot; # Gamma sigma (EV 3) set fmri(gammasigma3) 3 # Gamma delay (EV 3) set fmri(gammadelay3) 6 # Orthogonalise EV 3 wrt EV 0 set fmri(ortho3.0) 0 # Orthogonalise EV 3 wrt EV 1 set fmri(ortho3.1) 0 # Orthogonalise EV 3 wrt EV 2 set fmri(ortho3.2) 0 # Orthogonalise EV 3 wrt EV 3 set fmri(ortho3.3) 0 # Contrast &amp; F-tests mode # real : control real EVs # orig : control original EVs set fmri(con_mode_old) orig set fmri(con_mode) orig # Display images for contrast_real 1 set fmri(conpic_real.1) 1 # Title for contrast_real 1 set fmri(conname_real.1) &quot;&quot; # Real contrast_real vector 1 element 1 set fmri(con_real1.1) 0.0 # Real contrast_real vector 1 element 2 set fmri(con_real1.2) 0 # Real contrast_real vector 1 element 3 set fmri(con_real1.3) 1.0 # Real contrast_real vector 1 element 4 set fmri(con_real1.4) 0 # Real contrast_real vector 1 element 5 set fmri(con_real1.5) 0 # Real contrast_real vector 1 element 6 set fmri(con_real1.6) 0 # Display images for contrast_orig 1 set fmri(conpic_orig.1) 1 # Title for contrast_orig 1 set fmri(conname_orig.1) &quot;&quot; # Real contrast_orig vector 1 element 1 set fmri(con_orig1.1) 0.0 # Real contrast_orig vector 1 element 2 set fmri(con_orig1.2) 1.0 # Real contrast_orig vector 1 element 3 set fmri(con_orig1.3) 0 # Contrast masking - use &gt;0 instead of thresholding? set fmri(conmask_zerothresh_yn) 0 # Do contrast masking at all? set fmri(conmask1_1) 0 ########################################################## # Now options that do not appear in the GUI # Alternative (to BETting) mask image set fmri(alternative_mask) &quot;&quot; # Initial structural space registration initialisation transform set fmri(init_initial_highres) &quot;&quot; # Structural space registration initialisation transform set fmri(init_highres) &quot;&quot; # Standard space registration initialisation transform set fmri(init_standard) &quot;&quot; # For full FEAT analysis: overwrite existing .feat output dir? set fmri(overwrite_yn) 0 &#39; Now, we define the function that creates the fsf-file by filling the placeholders and writing to file. create_fsf &lt;- function(fsf = dsgn, placeholder = c(&quot;@n_vols@&quot;), replace_with = c(&quot;666&quot;), out_fn = NA){ assertthat::are_equal(length(placeholder), length(replace_with)) # loop over the placeholders and fill them with info for (i in 1:length(placeholder)){ fsf &lt;- gsub(pattern=placeholder[i], replacement = replace_with[i], x=fsf) } # write fsf file con&lt;-file(out_fn) writeLines(fsf, con) close(con) } Next, for each run and periodicity, let’s replace the placeholders with the required variables. # these are the placeholders in the fsf to_replace &lt;- c(&quot;@out_dir@&quot;, &quot;@func_fn@&quot;, &quot;@tr@&quot;, &quot;@n_vols@&quot;, &quot;@navi_ev_fn@&quot;, &quot;@cosine_ev_fn@&quot;, &quot;@feedback_ev_fn@&quot;, &quot;@conf_ev_fn@&quot;) for (i_sub in subjects){ for (i_run in runs){ # current functional data and find number of volumes in case they differ func_fn &lt;- here(&quot;data&quot;, &quot;FunctionalScans&quot;, &quot;4D&quot;, i_sub, i_run, paste0(i_run, &quot;_masked.nii.gz&quot;)) hdr &lt;- fslhd(func_fn, verbose =FALSE) hdr &lt;- hdr[grep(&quot;\\\\bdim4\\\\b&quot;, hdr)] n_vols &lt;- regmatches(hdr, gregexpr(&quot;[[:digit:]]+&quot;, hdr))[[1]][2] for (i_period in periodicities){ # folder to write the fsf-files to fsf_dir &lt;- here(&quot;data&quot;, &quot;glm2&quot;, &quot;glm2_secondhalf&quot;, &quot;cosine_pmod&quot;, &quot;feat_design&quot;, paste0(i_period, &quot;fold&quot;), i_sub, i_run) if(!dir.exists(fsf_dir)){dir.create(fsf_dir, recursive = TRUE)} # collect the info we need fsf_fn &lt;- file.path(fsf_dir, sprintf(&quot;%s_%s_%dfold.fsf&quot;, i_sub, i_run, i_period)) out_dir &lt;- here(&quot;data&quot;, &quot;glm2&quot;, &quot;glm2_secondhalf&quot;, &quot;cosine_pmod&quot;, paste0(i_period, &quot;fold&quot;), i_sub, i_run) tr &lt;- 1.5 navi_ev_fn &lt;- here(&quot;data&quot;, &quot;glm2&quot;, &quot;glm2_secondhalf&quot;, &quot;cosine_pmod&quot;, &quot;feat_ev&quot;, i_sub, i_run, &quot;translation.txt&quot;) cosine_ev_fn &lt;- here(&quot;data&quot;, &quot;glm2&quot;, &quot;glm2_secondhalf&quot;, &quot;cosine_pmod&quot;, &quot;feat_ev&quot;, i_sub, i_run, paste0(&quot;translation_cosine_&quot;, i_period, &quot;fold_half2.txt&quot;)) feedback_ev_fn &lt;- here(&quot;data&quot;, &quot;glm2&quot;, &quot;glm2_secondhalf&quot;, &quot;cosine_pmod&quot;, &quot;feat_ev&quot;, i_sub, i_run, &quot;feedback.txt&quot;) conf_ev_fn &lt;- here(&quot;data&quot;, &quot;AdditionalRegressors&quot;, i_sub, paste0(&quot;realignmentParameters_&quot;, i_run ,&quot;.txt&quot;)) # collect the filler items. CAVE: Must be in same order as to_replace fillers &lt;- c(out_dir, func_fn, tr, n_vols, navi_ev_fn, cosine_ev_fn, feedback_ev_fn, conf_ev_fn) # create the fsf file create_fsf(fsf = dsgn, placeholder = to_replace, replace_with = fillers, out_fn = fsf_fn) # create GLM design files to use with film_gls system(sprintf(&quot;%s/bin/feat_model %s %s&quot;, fsldir(), tools::file_path_sans_ext(fsf_fn), conf_ev_fn)) } } } 5.1.3 Run GLM2 We are ready to run GLM2. We will do so using FSL FEAT and the bare film_gls command. 5.1.3.1 FEAT Let’s start by running the GLM using FEAT. for (i_sub in subjects){ for (i_run in runs){ for (i_period in periodicities){ # check if the t-stats image exists, this should be one of the last files written fn &lt;- here(&quot;data&quot;, &quot;glm2&quot;, &quot;glm2_secondhalf&quot;, &quot;cosine_pmod&quot;, paste0(i_period, &quot;fold&quot;), i_sub, paste0(i_run, &quot;.feat&quot;), &quot;stats&quot;, &quot;tstat1.nii.gz&quot;) if (!file.exists(fn)){ # build the command and run fsf_fn &lt;- here(&quot;data&quot;, &quot;glm2&quot;, &quot;glm2_secondhalf&quot;, &quot;cosine_pmod&quot;, &quot;feat_design&quot;, paste0(i_period, &quot;fold&quot;), i_sub, i_run, sprintf(&quot;%s_%s_%dfold.fsf&quot;, i_sub, i_run, i_period)) cmd &lt;- sprintf(&quot;%s/bin/feat %s&quot;, fsldir(), fsf_fn) system(cmd) # remove the residuals file to clear some space system(sprintf(&quot;rm %s&quot;, here(&quot;data&quot;, &quot;glm2&quot;, &quot;glm2_secondhalf&quot;, &quot;cosine_pmod&quot;, paste0(i_period, &quot;fold&quot;), i_sub, paste0(i_run, &quot;.feat&quot;), &quot;stats&quot;, &quot;res4d.nii.gz&quot;))) } } } } Here is the design matrix as visualized by FEAT: GLM2 design matrix Covariance matrix &amp; design efficiency: 5.1.3.2 FILM_GLS The command here is based on the command used by FEAT. The results should thus be identical. NB: For this to work, make sure FSL is correctly configured. On MacOS that might mean starting RStudio from the terminal (open -na Rstudio). for (i_sub in subjects){ if (!dir.exists(here(&quot;data&quot;, &quot;glm2&quot;, &quot;glm2_secondhalf&quot;, &quot;cosine_pmod&quot;,paste0(i_period, &quot;fold&quot;), i_sub))) {dir.create(here(&quot;data&quot;, &quot;glm2&quot;, &quot;glm2_secondhalf&quot;, &quot;cosine_pmod&quot;,paste0(i_period, &quot;fold&quot;), i_sub))} for (i_run in runs){ for (i_period in periodicities){ # files and folders to be used as input for film_gls func_fn &lt;- here(&quot;data&quot;, &quot;FunctionalScans&quot;, &quot;4D&quot;, i_sub, i_run, paste0(i_run, &quot;_masked.nii.gz&quot;)) out_dir &lt;- here(&quot;data&quot;, &quot;glm2&quot;, &quot;glm2_secondhalf&quot;, &quot;cosine_pmod&quot;, paste0(i_period, &quot;fold&quot;), i_sub, i_run) pd_fn &lt;- here(&quot;data&quot;, &quot;glm2&quot;, &quot;glm2_secondhalf&quot;, &quot;cosine_pmod&quot;, &quot;feat_design&quot;, paste0(i_period, &quot;fold&quot;), i_sub, i_run, sprintf(&quot;%s_%s_%dfold.mat&quot;, i_sub, i_run, i_period)) con_fn &lt;- here(&quot;data&quot;, &quot;glm2&quot;, &quot;glm2_secondhalf&quot;, &quot;cosine_pmod&quot;, &quot;feat_design&quot;, paste0(i_period, &quot;fold&quot;), i_sub, i_run, sprintf(&quot;%s_%s_%dfold.con&quot;, i_sub, i_run, i_period)) # check if the zstat of the t-contrast exists, this should be one of the last files written fn &lt;- file.path(out_dir, &quot;tstat1.nii.gz&quot;) if (!file.exists(fn)){ # build the command and run t1 &lt;- Sys.time() cmd &lt;- sprintf(&quot;%s/bin/film_gls --in=%s --rn=%s --pd=%s --thr=1 --sa --ms=5 --con=%s&quot;, fsldir(), func_fn, out_dir, pd_fn, con_fn) system(cmd, intern = TRUE) Sys.time() - t1 # remove the residuals file to clear some space system(sprintf(&quot;rm %s&quot;, file.path(out_dir, &quot;res4d.nii.gz&quot;))) } } } } 5.1.4 GLM 2 results 5.1.4.1 Check if results are the same After running the analysis using FEAT and via film_gls directly, let’s check if the results are comparable. for (i_sub in subjects){ for (i_run in runs){ for (i_period in periodicities){ # load the t-Stat images fn1 &lt;- here(&quot;data&quot;, &quot;glm2&quot;, &quot;glm2_secondhalf&quot;, &quot;cosine_pmod&quot;, paste0(i_period, &quot;fold&quot;), i_sub, paste0(i_run, &quot;.feat&quot;), &quot;stats&quot;, &quot;tstat1.nii.gz&quot;) fn2 &lt;- here(&quot;data&quot;, &quot;glm2&quot;, &quot;glm2_secondhalf&quot;, &quot;cosine_pmod&quot;, paste0(i_period, &quot;fold&quot;), i_sub, i_run, &quot;tstat1.nii.gz&quot;) feat_nii &lt;- readNIfTI2(fn1) film_nii &lt;- readNIfTI2(fn2) # store in data frame stat_df &lt;- tibble(feat = c(feat_nii), film = c(film_nii)) # diagnostic plot p1 &lt;- ggplot(stat_df, aes(x=feat, y=film)) + geom_point() + theme_cowplot() + theme(aspect.ratio = 1) + labs(title = &quot;T-Statistics from FEAT and FILM&quot;, subtitle = sprintf(&quot;r=%.3f&quot;, cor(stat_df$feat, stat_df$film))) print(p1) } } } 5.1.4.2 Brain plot On the whole-brain level, we can plot the t-values of the parametric modulator across voxels. The plots below are arbitrarily thresholded at t &gt; 1.5. for (i_sub in subjects){ for (i_run in runs){ for (i_period in periodicities){ # load mean functional and t-values fn &lt;- here(&quot;data&quot;, &quot;glm2&quot;, &quot;glm2_secondhalf&quot;, &quot;cosine_pmod&quot;, paste0(i_period, &quot;fold&quot;), i_sub, paste0(i_run, &quot;.feat&quot;), &quot;mean_func.nii.gz&quot;) mean_func_nii &lt;- readNIfTI2(fn) fn &lt;- here(&quot;data&quot;, &quot;glm2&quot;, &quot;glm2_secondhalf&quot;, &quot;cosine_pmod&quot;, paste0(i_period, &quot;fold&quot;), i_sub, i_run, &quot;tstat1.nii.gz&quot;) t_nii &lt;- readNIfTI2(fn) f_nii[f_nii &lt; 1.5] &lt;- 0 # overlay t-values on mean func ortho2(mean_func_nii, f_nii, xyz = c(46,46,15), ycolorbar = TRUE, col.y = oro.nifti::hotmetal(10), ybreaks = seq(1.5,6.5,0.5)) } } } 5.1.4.3 EC results Let’s load the EC results into a dataframe. # tibble to store output stat_df &lt;- tibble() for (i_sub in subjects){ # load the right EC mask and linearize it ec_mask_nii &lt;- readNIfTI2(here(&quot;data&quot;, &quot;masks&quot;, &quot;ROI_masks&quot;, &quot;ROImask_entorhinalCortex_RH.nii&quot;)) ec_mask_lin &lt;- c(ec_mask_nii) # load the combined brain mask and linearize it brain_mask_nii &lt;- readNIfTI2(here(&quot;data&quot;, &quot;masks&quot;, &quot;brain_mask&quot;, i_sub, &quot;comb_brain_mask_tMean100.nii.gz&quot;)) brain_mask_lin &lt;- as.logical(c(brain_mask_nii)) for (i_run in runs){ for (i_period in periodicities){ # load the t-stat image #fn &lt;- here(&quot;data&quot;, &quot;glm2&quot;, &quot;glm2_secondhalf&quot;, &quot;cosine_pmod&quot;, paste0(i_period, &quot;fold&quot;), # i_sub, paste0(i_run, &quot;.feat&quot;), &quot;stats&quot;, &quot;tstat1.nii.gz&quot;) fn &lt;- here(&quot;data&quot;, &quot;glm2&quot;, &quot;glm2_secondhalf&quot;, &quot;cosine_pmod&quot;, paste0(i_period, &quot;fold&quot;), i_sub, i_run, &quot;tstat1.nii.gz&quot;) stat_nii &lt;- readNIfTI2(fn) # store in data frame temp_stat_df &lt;- tibble(subID = i_sub, periodicity = i_period, run = i_run, pmod_t = c(stat_nii)[brain_mask_lin==1], ec = as.logical(ec_mask_lin[brain_mask_lin==1]), vox = which(brain_mask_lin==1)) stat_df &lt;- rbind(stat_df, temp_stat_df) } } } Plot the results for the entorhinal cortex ROI. The boxplot shows the distribution of t-values across entorhinal voxels. # boxplot of t-values of cosine regressor ggplot(stat_df %&gt;% filter(ec == TRUE), aes(x=run, y=pmod_t)) + geom_boxplot(width=0.3, fill=&quot;darkgrey&quot;) + geom_point(position = position_nudge(x = +0.2)) + theme_cowplot() The scatter plot shows the relationship of t-values from the same voxels across the two runs. # scatter plot with one dot per voxel ggplot(stat_df %&gt;% filter(ec == TRUE) %&gt;% pivot_wider(names_from = run, values_from = pmod_t), aes(x=run01, y=run02)) + geom_point() + geom_smooth(formula = &quot;y ~ x&quot;, method=&quot;lm&quot;, color=&quot;darkred&quot;) + theme_cowplot() + theme(aspect.ratio = 1) "],["credit.html", "6 Credit 6.1 GridCAT 6.2 Hosting on GitPages 6.3 Publishing on GitHub Pages 6.4 List of R packages 6.5 References 6.6 Session Info", " 6 Credit 6.1 GridCAT This example pipeline uses the data that accompanies the GridCAT toolbox. Here is the reference to the toolbox: Stangl, M., Shine, J., &amp; Wolbers, T. (2017). The GridCAT: A Toolbox for Automated Analysis of Human Grid Cell Codes in fMRI. Frontiers in Neuroinformatics, 11. https://doi.org/10.3389/fninf.2017.00047 The data can be downloaded from here. 6.2 Hosting on GitPages 6.3 Publishing on GitHub Pages To be able to host the HTML output using GitPages, we need to include a file called .nojekyll in the docs folder where the HTML documentation is stored. Let’s create this file if it doesn’t exist yet. if (!file.exists(here(&quot;docs&quot;, &quot;.nojekyll&quot;))){ file.create(here(&quot;docs&quot;, &#39;.nojekyll&#39;)) } 6.4 List of R packages Here is a list of packages used in the analysis and references to them. It is created using the grateful package. Unfortunately, not all packages provide all information, so there are a few warning messages. The code below generates a markdown file with references that we read in and print below. grateful::get_csl(&quot;apa-6th-edition&quot;) file.copy(from=here(&quot;apa-6th-edition.csl&quot;), to=here(&quot;code&quot;, &quot;apa-6th-edition.csl&quot;)) grateful::cite_packages(all.pkg = FALSE, include.rmd=FALSE, style = &quot;apa-6th-edition&quot;, out.format = &quot;md&quot;, out.dir = here(&quot;code&quot;)) ## ## ## processing file: refs.Rmd ## output file: refs.knit.md ## ## Output created: code/citations.md used_pkgs &lt;-readLines(here(&quot;code&quot;, &quot;citations.md&quot;)) # the chunk above produced some output we delete because we don&#39;t need it file.remove(here(&quot;code&quot;, &quot;apa-6th-edition.csl&quot;)) [1] TRUE #file.remove(here(&quot;apa-6th-edition.csl&quot;)) file.remove(here(&quot;code&quot;, &quot;pkg-refs.bib&quot;)) [1] TRUE file.remove(here(&quot;code&quot;, &quot;citations.md&quot;)) [1] TRUE # print the references ref_line &lt;- which(used_pkgs==&quot;References&quot;) used_pkgs[ref_line] &lt;- &quot;### References {-}&quot; used_pkgs[ref_line+1] &lt;- &quot;&quot; paste(used_pkgs, collapse = &#39;\\n&#39;) %&gt;% cat() base (R Core Team, 2021) grateful (Rodríguez-Sánchez &amp; Hutchins, 2020) remotes (Csárdi et al., 2021) circular (Agostinelli &amp; Lund, 2017) useful (Lander, 2018) cowplot (Wilke, 2020) fslr (fslr?) neurobase (Muschelli, 2021) oro.nifti (Whitcher, Schmid, &amp; Thornton, 2011) here (Müller, 2020) forcats (Wickham, 2021a) stringr (Wickham, 2019) dplyr (Wickham, François, Henry, &amp; Müller, 2021) purrr (Henry &amp; Wickham, 2020) readr (Wickham, Hester, &amp; Bryan, 2021) tidyr (Wickham, 2021b) tibble (Müller &amp; Wickham, 2021) ggplot2 (Wickham, 2016) tidyverse (Wickham et al., 2019) bookdown (Xie, 2016) 6.5 References Agostinelli, C., &amp; Lund, U. (2017). R package circular: Circular statistics (version 0.4-93). CA: Department of Environmental Sciences, Informatics; Statistics, Ca’ Foscari University, Venice, Italy. UL: Department of Statistics, California Polytechnic State University, San Luis Obispo, California, USA. Retrieved from https://r-forge.r-project.org/projects/circular/ Csárdi, G., Hester, J., Wickham, H., Chang, W., Morgan, M., &amp; Tenenbaum, D. (2021). Remotes: R package installation from remote repositories, including ’GitHub’. Retrieved from https://CRAN.R-project.org/package=remotes Henry, L., &amp; Wickham, H. (2020). Purrr: Functional programming tools. Retrieved from https://CRAN.R-project.org/package=purrr Lander, J. P. (2018). Useful: A collection of handy, useful functions. Retrieved from https://CRAN.R-project.org/package=useful Müller, K. (2020). Here: A simpler way to find your files. Retrieved from https://CRAN.R-project.org/package=here Müller, K., &amp; Wickham, H. (2021). Tibble: Simple data frames. Retrieved from https://CRAN.R-project.org/package=tibble Muschelli, J. (2021). Neurobase: ’Neuroconductor’ base package with helper functions for ’nifti’ objects. Retrieved from https://CRAN.R-project.org/package=neurobase R Core Team. (2021). R: A language and environment for statistical computing. Vienna, Austria: R Foundation for Statistical Computing. Retrieved from https://www.R-project.org/ Rodríguez-Sánchez, F., &amp; Hutchins, S. D. (2020). Grateful: Facilitate citation of r packages. Retrieved from https://github.com/Pakillo/grateful Whitcher, B., Schmid, V. J., &amp; Thornton, A. (2011). Working with the DICOM and NIfTI data standards in R. Journal of Statistical Software, 44(6), 1–28. Retrieved from https://www.jstatsoft.org/v44/i06/ Wickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. Retrieved from https://ggplot2.tidyverse.org Wickham, H. (2019). Stringr: Simple, consistent wrappers for common string operations. Retrieved from https://CRAN.R-project.org/package=stringr Wickham, H. (2021a). Forcats: Tools for working with categorical variables (factors). Retrieved from https://CRAN.R-project.org/package=forcats Wickham, H. (2021b). Tidyr: Tidy messy data. Retrieved from https://CRAN.R-project.org/package=tidyr Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., … Yutani, H. (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686. https://doi.org/10.21105/joss.01686 Wickham, H., François, R., Henry, L., &amp; Müller, K. (2021). Dplyr: A grammar of data manipulation. Retrieved from https://CRAN.R-project.org/package=dplyr Wickham, H., Hester, J., &amp; Bryan, J. (2021). Readr: Read rectangular text data. Retrieved from https://CRAN.R-project.org/package=readr Wilke, C. O. (2020). Cowplot: Streamlined plot theme and plot annotations for ’ggplot2’. Retrieved from https://CRAN.R-project.org/package=cowplot Xie, Y. (2016). Bookdown: Authoring books and technical documents with R markdown. Boca Raton, Florida: Chapman; Hall/CRC. Retrieved from https://bookdown.org/yihui/bookdown 6.6 Session Info Lastly, we run session info, using the version from the devtools package. sessionInfo() ## R version 4.1.1 (2021-08-10) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Big Sur 11.6.1 ## ## Matrix products: default ## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] grateful_0.0.3 remotes_2.4.2 circular_0.4-93 useful_1.2.6 cowplot_1.1.1 fslr_2.24.1 ## [7] neurobase_1.32.1 oro.nifti_0.11.0 here_1.0.1 forcats_0.5.1 stringr_1.4.0 dplyr_1.0.7 ## [13] purrr_0.3.4 readr_2.1.1 tidyr_1.1.4 tibble_3.1.6 ggplot2_3.3.5 tidyverse_1.3.1 ## [19] bookdown_0.24 ## ## loaded via a namespace (and not attached): ## [1] nlme_3.1-152 bitops_1.0-7 matrixStats_0.61.0 fs_1.5.2 lubridate_1.8.0 bit64_4.0.5 ## [7] httr_1.4.2 rprojroot_2.0.2 tools_4.1.1 backports_1.4.1 utf8_1.2.2 R6_2.5.1 ## [13] mgcv_1.8-36 DBI_1.1.2 colorspace_2.0-2 withr_2.4.3 tidyselect_1.1.1 bit_4.0.4 ## [19] compiler_4.1.1 cli_3.1.0 rvest_1.0.2 xml2_1.3.3 labeling_0.4.2 scales_1.1.1 ## [25] mvtnorm_1.1-3 digest_0.6.29 rmarkdown_2.11 R.utils_2.11.0 RNifti_1.3.1 pkgconfig_2.0.3 ## [31] htmltools_0.5.2 dbplyr_2.1.1 fastmap_1.1.0 highr_0.9 rlang_0.4.12 readxl_1.3.1 ## [37] rstudioapi_0.13 jquerylib_0.1.4 generics_0.1.1 farver_2.1.0 jsonlite_1.7.2 vroom_1.5.7 ## [43] R.oo_1.24.0 magrittr_2.0.1 Matrix_1.3-4 Rcpp_1.0.7 munsell_0.5.0 fansi_0.5.0 ## [49] abind_1.4-5 lifecycle_1.0.1 R.methodsS3_1.8.1 stringi_1.7.6 yaml_2.2.1 plyr_1.8.6 ## [55] grid_4.1.1 parallel_4.1.1 crayon_1.4.2 lattice_0.20-44 haven_2.4.3 splines_4.1.1 ## [61] hms_1.1.1 knitr_1.37 pillar_1.6.4 boot_1.3-28 reprex_2.0.1 glue_1.6.0 ## [67] evaluate_0.14 modelr_0.1.8 vctrs_0.3.8 tzdb_0.2.0 cellranger_1.1.0 gtable_0.3.0 ## [73] assertthat_0.2.1 xfun_0.29 broom_0.7.11 ellipsis_0.3.2 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
